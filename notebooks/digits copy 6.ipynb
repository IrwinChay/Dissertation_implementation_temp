{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate a PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:00.305482Z",
     "start_time": "2024-03-14T14:35:59.231534Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:01.996183Z",
     "start_time": "2024-03-14T14:36:01.950399Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")  # The device to use, e.g., \"cpu\", \"cuda\", \"cuda:1\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:03.245505Z",
     "start_time": "2024-03-14T14:36:03.190582Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:05.899377Z",
     "start_time": "2024-03-14T14:36:05.858609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcab8b298d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(4)\n",
    "np.random.seed(4)\n",
    "torch.manual_seed(4)\n",
    "# if 'cuda' in device.type:\n",
    "#     torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and test splits of MNIST, and preprocess them by flattening the tensor images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:10.329915Z",
     "start_time": "2024-03-14T14:36:09.956962Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (255 * x.view(-1)).long())\n",
    "])\n",
    "data_train = datasets.MNIST('datasets', train=True, download=True, transform=transform)\n",
    "data_test = datasets.MNIST('datasets', train=False, download=True, transform=transform)\n",
    "num_variables = data_train[0][0].shape[0]\n",
    "height, width = 28, 28\n",
    "print(f\"Number of variables: {num_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T12:41:27.661486Z",
     "start_time": "2024-03-14T12:41:27.534444Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(data_train[0][0].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Class: {data_train[0][1]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3137ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37115b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from uci_datasets import Dataset\n",
    "\n",
    "from ignite.engine import Events, Engine\n",
    "from ignite.metrics import Average, Loss\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.mlls import VariationalELBO\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the region graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e4bf454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.region_graph.poon_domingos import PoonDomingos\n",
    "from cirkit.region_graph.random_binary_tree import RandomBinaryTree\n",
    "from cirkit.region_graph.fully_factorized import FullyFactorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1a2c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.models.gp import CircuitGP, initial_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a _Quad Graph_ region graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:19.883137Z",
     "start_time": "2024-03-14T14:36:19.844640Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Others available region graphs are _Poon Domingos_ and _QuadTree_, whose imports are showed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:18.569812Z",
     "start_time": "2024-03-14T14:36:18.526134Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to choose both the input and inner layers of our circuit. As input layer we select the _CategoricalLayer_ with 256 categories (the number of pixel values). For the inner layer instead, we choose the _uncollapsed CP_ layer with rank 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:22.044953Z",
     "start_time": "2024-03-14T14:36:21.997532Z"
    }
   },
   "outputs": [],
   "source": [
    "from cirkit.layers.input.exp_family import CategoricalLayer\n",
    "from cirkit.layers.sum_product import CPLayer\n",
    "from cirkit.layers.input.rbf_kernel_flatten import RBFKernelFlattenLayer\n",
    "\n",
    "efamily_cls = RBFKernelFlattenLayer   # Flatten\n",
    "efamily_kwargs = {}\n",
    "layer_cls = CPLayer\n",
    "layer_kwargs = {'rank': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the tensorized PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build our tensorized PC by specifying the region graph and layers we chose previously. In addition, we can scale the architecture by increasing the number of input and inner units. We can also have circuits with multiple output units by choosing _num_classes > 1_. However, in this notebook we only estimate the distribution of the images and marginalize out the class variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure weights are non-negative we reparametrize them via exponentiation. Several reparametrization functions are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f01d2ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.region_graph.quad_tree import QuadTree\n",
    "# region_graph = QuadTree(width, height, struct_decomp=False)\n",
    "# region_graph = RandomBinaryTree(num_vars=8, depth=3, num_repetitions=6)\n",
    "region_graph = FullyFactorized(num_vars=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:23.646351Z",
     "start_time": "2024-03-14T14:36:23.593945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorizedPC(\n",
      "  (input_layer): RBFKernelFlattenLayer(\n",
      "    (params): ReparamExp()\n",
      "  )\n",
      "  (scope_layer): ScopeLayer()\n",
      "  (inner_layers): ModuleList(\n",
      "    (0): CollapsedCPLayer(\n",
      "      (params_in): ReparamSoftmax()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from cirkit.reparams.leaf import ReparamExp, ReparamLogSoftmax, ReparamSoftmax\n",
    "from cirkit.models.tensorized_circuit import TensorizedPC\n",
    "pc = TensorizedPC.from_region_graph(\n",
    "    region_graph,\n",
    "    num_inner_units=100,\n",
    "    num_input_units=100,\n",
    "    efamily_cls=efamily_cls,\n",
    "    efamily_kwargs=efamily_kwargs,\n",
    "    layer_cls=layer_cls,\n",
    "    layer_kwargs=layer_kwargs,\n",
    "    num_classes=1,\n",
    "    reparam=ReparamSoftmax # ReparamLogSoftmax #  ReparamSoftmax\n",
    ")\n",
    "pc.to(device)\n",
    "print(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "be79dbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 100])\n",
      "torch.Size([1, 100, 1])\n"
     ]
    }
   ],
   "source": [
    "for param in pc.parameters(): \n",
    "    print (param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e4b879cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2700\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in pc.parameters() if p.requires_grad)\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "baaefe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kin40k dataset, N=40000, d=8\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(\"kin40k\")\n",
    "x_train, y_train, x_test, y_test = data.get_split(split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8905bdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36000, 8), (4000, 8))"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "42d1accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_real = x_train[:32000] #32000 # 2053   36584    36584     39063   13281    2672   # RE-RUN # 13279   # 1279   4701  824\n",
    "y_train_real = y_train[:32000]\n",
    "y_train_real = y_train_real.squeeze()\n",
    "x_val = x_train[32000:]\n",
    "y_val = y_train[32000:]\n",
    "y_val = y_val.squeeze()\n",
    "y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "84cc07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x_train_real.mean(axis=0)\n",
    "std = x_train_real.std(axis=0)\n",
    "\n",
    "x_train_real_normalized = (x_train_real - mean) / std\n",
    "x_val_normalized = (x_val - mean) / std\n",
    "x_test_normalized = (x_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "04a58de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class IdentityMapping(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentityMapping, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a74111ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 4.3568e+03,  2.0165e+02, -7.6162e-02,  5.0537e+01,  6.1556e+05,\n",
      "         6.7965e+01,  8.5420e+02, -4.7975e+01, -6.8170e+00]), tensor(-1.8912))\n",
      "(tensor([-2.8508e+03, -4.6753e+02,  6.0788e-02, -4.6812e+01, -4.3633e+05,\n",
      "        -1.7177e+01,  8.4624e+01, -4.2975e+01, -1.1136e-01]), tensor(0.9737))\n",
      "(tensor([ 4.6787e+03,  5.9385e+02, -5.4212e-02,  9.8102e+01,  6.6254e+05,\n",
      "         1.0982e+02,  9.7232e+02,  6.9025e+01, -7.8412e+00]), tensor(-0.5134))\n",
      "(tensor([ 1.1472e+04,  2.6860e+03, -3.5182e-02,  1.8665e+02,  1.5292e+06,\n",
      "         1.7410e+02,  2.5700e+03,  2.1602e+02, -1.5885e+01]), tensor(-0.9630))\n",
      "(tensor([ 7.2802e+03,  1.6162e+03, -3.2252e-02,  1.2412e+02,  1.0695e+06,\n",
      "         1.3790e+02,  1.5315e+03,  2.8025e+01, -1.2329e+01]), tensor(-0.5702))\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(ds_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6f58cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Define the linear layer with input dimension 8 and output dimension 256\n",
    "        self.linear = nn.Linear(in_features=8, out_features=128)\n",
    "        # Define the ReLU activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply linear layer and then ReLU activation to the input x\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d7d527e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 32000 datapoints for 50 epochs\n",
      "f_X_samples torch.Size([1000, 8])\n",
      "initial_lengthscale tensor(3.8970)\n",
      "All circuit parameters shape: \n",
      "torch.Size([8, 100])\n",
      "torch.Size([1, 100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irwinchay/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(24)\n",
    "torch.manual_seed(24) ####################### CHANGE\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# X_train, y_train = make_data(n_samples)\n",
    "# X_test, y_test = X_train, y_train\n",
    "\n",
    "# x_train, y_train, x_test, y_test\n",
    "\n",
    "ds_train = torch.utils.data.TensorDataset(torch.from_numpy(x_train_real_normalized).float(), torch.from_numpy(y_train_real).float())\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, drop_last=True) # suffle \n",
    "\n",
    "ds_val = torch.utils.data.TensorDataset(torch.from_numpy(x_val_normalized).float(), torch.from_numpy(y_val).float())\n",
    "dl_val = torch.utils.data.DataLoader(ds_val, batch_size=512, shuffle=False)\n",
    "\n",
    "ds_test = torch.utils.data.TensorDataset(torch.from_numpy(x_test_normalized).float(), torch.from_numpy(y_test).float())\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=512, shuffle=False)\n",
    "\n",
    "# steps = 5e3\n",
    "epochs = 50\n",
    "print(f\"Training with {len(x_train_real)} datapoints for {epochs} epochs\")\n",
    "\n",
    "# Change this boolean to False for SNGP\n",
    "\n",
    "input_dim = 8 # input di  # 128\n",
    "\n",
    "num_outputs = 1 # regression with 1D output\n",
    "\n",
    "feature_extractor = IdentityMapping()\n",
    "\n",
    "n_inducing_points = 50\n",
    "kernel = \"HBF\" ################# change \n",
    "\n",
    "initial_inducing_points, initial_lengthscale = initial_values(\n",
    "        ds_train, feature_extractor, n_inducing_points\n",
    ")\n",
    "\n",
    "gp_model = CircuitGP(\n",
    "    num_outputs=num_outputs,\n",
    "    num_features=input_dim,          # CHANGE features / input_dim\n",
    "    initial_lengthscale=initial_lengthscale,\n",
    "    initial_inducing_points=initial_inducing_points,\n",
    "    circuit=pc\n",
    "    # kernel=kernel,\n",
    ")\n",
    "    \n",
    "likelihood = GaussianLikelihood()\n",
    "elbo_fn = VariationalELBO(likelihood, gp_model, num_data=len(ds_train))\n",
    "loss_fn = lambda x, y: -elbo_fn(x, y)\n",
    "    \n",
    "# learning rate   \n",
    "lr = 1e-3\n",
    "\n",
    "parameters = [\n",
    "    {\"params\": gp_model.parameters(), \"lr\": lr},\n",
    "]\n",
    "parameters.append({\"params\": likelihood.parameters(), \"lr\": lr})\n",
    "    \n",
    "optimizer = torch.optim.Adam(parameters)\n",
    "pbar = ProgressBar()\n",
    "\n",
    "step_counter = 0\n",
    "\n",
    "def step(engine, batch):\n",
    "    \n",
    "    global step_counter\n",
    "    step_counter += 1\n",
    "    \n",
    "    gp_model.train()\n",
    "    likelihood.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x, y = batch\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    y_pred = gp_model(x) # get y    \n",
    "    loss = loss_fn(y_pred, y) # loss\n",
    "\n",
    "    \n",
    "    if torch.isnan(loss).any():\n",
    "        print(f\"Step {step_counter}: NaN detected in loss.\")\n",
    "        print(\"loss\", loss)\n",
    "        print(\"y_pred\", y_pred)\n",
    "    \n",
    "    if torch.isnan(loss).any():\n",
    "        print(\"NaN detected in loss, saving model and stopping.\")\n",
    "        # Save model weights before termination\n",
    "        torch.save(gp_model.state_dict(), 'model_weights_before_nan.pt')\n",
    "        engine.terminate()\n",
    "        return\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    gp_model.eval() # set to eval\n",
    "    likelihood.eval()\n",
    "    \n",
    "    x, y = batch\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    y_pred = gp_model(x)   \n",
    "    return y_pred, y\n",
    "\n",
    "    \n",
    "trainer = Engine(step)\n",
    "evaluator = Engine(eval_step)\n",
    "\n",
    "metric = Average()\n",
    "metric.attach(trainer, \"loss\")\n",
    "pbar.attach(trainer)\n",
    "\n",
    "metric = Loss(lambda y_pred, y: - likelihood.expected_log_prob(y, y_pred).mean())\n",
    "\n",
    "metric.attach(evaluator, \"loss\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=int(epochs/20) + 1))\n",
    "def log_results(trainer):\n",
    "    evaluator.run(dl_val) # val dataset\n",
    "    print(f\"Results - Epoch: {trainer.state.epoch} - \"\n",
    "          f\"Val Loss: {evaluator.state.metrics['loss']:.2f} - \"\n",
    "          f\"Train Loss: {trainer.state.metrics['loss']:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e7cab3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 8])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 50])\n",
      "torch.Size([8, 100])\n",
      "torch.Size([1, 100, 1])\n",
      "torch.Size([1])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for index, param in enumerate(gp_model.parameters()): \n",
    "    # if (index==2):\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "82340f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd2f001e21543e19778613e98dc2a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd74ae3cac5f4a11984995832ee2de3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567eecbc60b64620bf77ca10f1b07b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 3 - Val Loss: 1.17 - Train Loss: 1.22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab2d01f2d80469e9e4101b81d9e8310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6753f78c42468cbf7f054fb8bafee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a9bab63b904f848ede937bb6e6383c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 6 - Val Loss: 1.03 - Train Loss: 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddcdac6ef2e4742a4cbf4bd2345a61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cb5e435f0c446d937604af65298c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221ec3b713f8411b9327028eb9615357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 9 - Val Loss: 0.99 - Train Loss: 0.98\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3406724138f4d2f9362be36a50ed412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4ff791c96c428e8b829ec98d47389b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541aa3ded51642b6aa884e33d2e7a7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 12 - Val Loss: 0.96 - Train Loss: 0.94\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505ad1cc90c0459d95daf6623d2e2317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e99693d25f2492cbd2dd2f2cb002506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31a7dcd47f74fb9a23656023daadc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 15 - Val Loss: 0.92 - Train Loss: 0.91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046e10b02acb4517abcb7a0455d0fccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c634a717f334557a4220ec523771c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f842a0d6f87e45b2b7752f2e89840967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 18 - Val Loss: 0.88 - Train Loss: 0.88\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bca5eca481419a89c616936ab9801f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa5e31c22064a5cb33a2f984704b640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e39bfef0f4413ea792adb8175e7a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 21 - Val Loss: 0.84 - Train Loss: 0.84\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23aab513b34c434f8b4d89f015269770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c2f06c5dbd4d469e32f97e00e18fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7456b8a307fe473b960f9dc139cf21bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 24 - Val Loss: 0.81 - Train Loss: 0.80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc75918813f49e7b39763e0c98834d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d3fe0995854e8d8024763b3e76080e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d339130cf664c24b81cd04e8a80ff22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 27 - Val Loss: 0.79 - Train Loss: 0.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb98ebb2ba7f4cf2ae771b5eeaad615c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a80c17cdf2472b88c371291b02591e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadd52d4caa24db6a939ff2436ef0645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 30 - Val Loss: 0.77 - Train Loss: 0.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d2861b23734db9a4d41d45e9f5dbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da1450e0af94ff29221709f69e97355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0804daeed0de4f198276e3c3d0ac2b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 33 - Val Loss: 0.75 - Train Loss: 0.75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5ce11283e74ffbba907f8e507303a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf5b4f942954ddf841787cfe4ab09d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1aa652416940ab8a7d47a589005b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 36 - Val Loss: 0.73 - Train Loss: 0.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8d7a368f0e426fa4f8918276b44a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd929cb250f0413ea341ba66585053a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3725e0fc6ae4465a83b18ea3bebc3e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 39 - Val Loss: 0.71 - Train Loss: 0.71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b285ed85234563aca6f7c635fe1113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf23ff4dbb34043b132ed34d9f3237a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6a947be4ba4fd6a217099728b4e879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 42 - Val Loss: 0.70 - Train Loss: 0.70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f59181cd01458b900eac8d2a01a55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956dfd2279634aad9f6ec40953736ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d77dd3149c64ac899b32ed7fe8c3910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 45 - Val Loss: 0.67 - Train Loss: 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b91ed4936748a6b2a67656049c3fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c2c72fd8b248a791fab789b91ca20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf5100ad1b04802970e6ba20da5fca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 48 - Val Loss: 0.65 - Train Loss: 0.65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ce628a46a0420bae747de5512f4cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b2e94758b84cf7bdb871a87d37ca7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 50000\n",
       "\tepoch: 50\n",
       "\tepoch_length: 1000\n",
       "\tmax_epochs: 50\n",
       "\toutput: 0.5384544134140015\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(dl_train, max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537363e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in likelihood.parameters(): \n",
    "    print (param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c666fe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.38\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ignite.metrics import RootMeanSquaredError\n",
    "import torch\n",
    "\n",
    "# Assuming you have a function to compute RMSE, or you're using Ignite's RMSE metric\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    gp_model.eval()  # Ensure model is in evaluation mode\n",
    "    likelihood.eval()\n",
    "    \n",
    "    x, y = batch\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    # Assuming your model outputs a distribution, e.g., MultivariateNormal\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        distribution = gp_model(x)\n",
    "        y_pred = distribution.mean  # Use the mean of the distribution as the prediction\n",
    "\n",
    "    return y_pred, y\n",
    "\n",
    "# Update the evaluator engine\n",
    "evaluator = Engine(eval_step)\n",
    "\n",
    "# Attach the RMSE metric to the evaluator\n",
    "rmse = RootMeanSquaredError()\n",
    "rmse.attach(evaluator, \"RMSE\")\n",
    "\n",
    "# After training, run the evaluator on the test dataset to compute the RMSE\n",
    "evaluator.run(dl_test)\n",
    "\n",
    "# Retrieve and display the RMSE\n",
    "test_rmse = evaluator.state.metrics['RMSE']\n",
    "print(f\"Test RMSE: {test_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b5f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37ce73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c2c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fb408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5011843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed631b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d906bdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13f66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1c1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8794c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed311e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0798ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:25.724719Z",
     "start_time": "2024-03-14T14:36:25.680948Z"
    }
   },
   "outputs": [],
   "source": [
    "pc.input_layer.params.param.shape\n",
    "# (self.num_vars, self.num_output_units, self.num_replicas, self.num_suff_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:35:35.437628Z",
     "start_time": "2024-03-14T14:35:35.393853Z"
    }
   },
   "outputs": [],
   "source": [
    "pc.scope_layer.scope.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:27.302533Z",
     "start_time": "2024-03-14T14:36:27.260539Z"
    }
   },
   "outputs": [],
   "source": [
    "pc.inner_layers[0].params_in() #.param #.shape #.param.shape\n",
    "# (F, H, I, O)\n",
    "# (fold count, arity, input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:11:52.080085Z",
     "start_time": "2024-03-14T13:11:52.073368Z"
    }
   },
   "outputs": [],
   "source": [
    "from cirkit.models.rbf_kernel import RBFCircuitKernel\n",
    "\n",
    "circuit_kernel = RBFCircuitKernel(pc, batch_shape=torch.Size([]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:06:06.337943Z",
     "start_time": "2024-03-14T13:06:06.330408Z"
    }
   },
   "outputs": [],
   "source": [
    "circuit_kernel(x1.squeeze(), x2.squeeze()).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:06:07.504758Z",
     "start_time": "2024-03-14T13:06:07.498492Z"
    }
   },
   "outputs": [],
   "source": [
    "x1.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:06:09.102855Z",
     "start_time": "2024-03-14T13:06:09.096848Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57dea52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4666592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "pc.input_layer.params.param = torch.nn.Parameter(torch.log(torch.ones(tuple(pc.input_layer.params.shape))*3.3))\n",
    "# pc.inner_layers[0].params_in.param = torch.nn.Parameter(torch.log(0.25*torch.ones(tuple(pc.inner_layers[0].params_in.shape))))\n",
    "# pc.inner_layers[0].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[0].params_in.shape))*3.3)\n",
    "# pc.inner_layers[1].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[1].params_in.shape))*3.3)\n",
    "# pc.inner_layers[2].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[2].params_in.shape))*3.3)\n",
    "# pc.inner_layers[3].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[3].params_in.shape))*3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a99ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.inner_layers[0].params_in() #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(3, 8, 1)\n",
    "x2 = torch.randn(3, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc(x1, x2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pc(x1, x2): \n",
    "    return pc(x1.unsqueeze(-1), x2.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "eval_pc(x1.squeeze(), x2.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel\n",
    "\n",
    "# x = torch.randn(3, 5)\n",
    "covar_module = RBFKernel()\n",
    "covar_module.lengthscale = torch.tensor(3.3)\n",
    "covar_module(x1.squeeze(), x2.squeeze()).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c4d3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel\n",
    "x = torch.randn(3, 2)\n",
    "RBFKernel().lengthscale = torch.tensor(3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RBF input output = RBF kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel, SpectralMixtureKernel\n",
    "\n",
    "x = torch.randn(3, 5)\n",
    "covar_module = SpectralMixtureKernel(num_mixtures=2, ard_num_dims=5)\n",
    "covar_module.mixture_scales = torch.tensor(3.3).expand(1, 2, 1, 5)\n",
    "covar_module.mixture_means = torch.tensor(2.2).expand(1, 2, 1, 5)\n",
    "covar_module.mixture_weights = torch.tensor([0.5]).expand(1, 2, 1, 5)\n",
    "covar_module(x).evaluate()\n",
    "# covar_module.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.sm_kernel import SMKernelLayer\n",
    "input_la = SMKernelLayer(num_vars=5, num_output_units=1)\n",
    "\n",
    "input_la.params = torch.nn.Parameter(torch.ones((5,1))*3.3)\n",
    "\n",
    "# input_la(x1, x2).squeeze().shape\n",
    "\n",
    "# input_la(x.unsqueeze(-1), x.unsqueeze(-1)).shape\n",
    "\n",
    "torch.prod(torch.exp(input_la(x.unsqueeze(-1), x.unsqueeze(-1)).squeeze()), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f025e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_la = RBFKernelLayer(num_vars=20, num_output_units=1)\n",
    "\n",
    "input_la.params = torch.nn.Parameter(torch.ones((20,1))*3.3)\n",
    "\n",
    "# input_la(x1, x2).squeeze().shape\n",
    "torch.prod(input_la(x1, x1).squeeze(), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facf1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel\n",
    "\n",
    "x = torch.randn(3, 5)\n",
    "covar_module = RBFKernel()\n",
    "covar_module.lengthscale = torch.tensor(3.3)\n",
    "covar_module(x).evaluate()\n",
    "# covar_module.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0dc104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.rbf_kernel import RBFKernelLayer\n",
    "input_la = RBFKernelLayer(num_vars=5, num_output_units=1)\n",
    "\n",
    "input_la.params.param = torch.nn.Parameter(torch.log(torch.ones(tuple(input_la.params.shape))*3.3))\n",
    "# pc.input_layer.params.param = torch.nn.Parameter(torch.log(torch.ones(tuple(pc.input_layer.params.shape))*3.3))\n",
    "\n",
    "# input_la(x1, x2).squeeze().shape\n",
    "\n",
    "# input_la(x.unsqueeze(-1), x.unsqueeze(-1)).shape\n",
    "\n",
    "torch.prod(torch.exp(input_la(x.unsqueeze(-1), x.unsqueeze(-1)).squeeze()), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd562b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd606c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(0, 1, 3)\n",
    "torch.sin(train_x * (2 * math.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a2c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "# train_x = torch.linspace(0, 1, 3)\n",
    "# train_y = torch.sin(train_x * (2 * math.pi))\n",
    "train_x = torch.rand((3, 5))\n",
    "train_y = torch.rand((3))\n",
    "\n",
    "covar_module = SpectralMixtureKernel(num_mixtures=4, ard_num_dims=5)\n",
    "covar_module.initialize_from_data(train_x, train_y)\n",
    "covar_module(train_x).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f94551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.sm_kernel import SMKernelLayer\n",
    "input_la = SMKernelLayer(num_vars=1, num_output_units=4)\n",
    "\n",
    "input_la.params_mu.param = torch.nn.Parameter(covar_module.mixture_means)\n",
    "input_la.params_sigma.param = torch.nn.Parameter(torch.log(covar_module.mixture_scales))\n",
    "\n",
    "\n",
    "to_be_weighted = input_la(train_x.unsqueeze(-1), train_x.unsqueeze(-1))\n",
    "\n",
    "to_be_weighted = torch.prod(to_be_weighted, dim=2, keepdim=True) / 5\n",
    "\n",
    "tensor1_expanded = covar_module.mixture_weights.expand_as(to_be_weighted.squeeze(-1))\n",
    "\n",
    "# Element-wise multiplication and then sum over the inner product dimension (dimension 3 after squeeze)\n",
    "(tensor1_expanded * to_be_weighted.squeeze(-1)).sum(dim=3).squeeze()\n",
    "\n",
    "# torch.prod(finalfinal, dim=-1, keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_module.mixture_scales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b267ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_module(x1).evaluate().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d377b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.unsqueeze(-1).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = torch.tensor([[-0.6281], [ 0.1011], [ 0.0664]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.rbf_kernel import RBFKernelLayer\n",
    "input_la = RBFKernelLayer(num_vars=2, num_output_units=1)\n",
    "\n",
    "input_la.params = torch.nn.Parameter(torch.ones((1,1))*3.3)\n",
    "\n",
    "input_la(x_2.unsqueeze(-1), x_2.unsqueeze(-1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45183425",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_la.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a28677",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones((2,1))*3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.unsqueeze(-1).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed03208",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_la(x.unsqueeze(-1), x.unsqueeze(-1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756535e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cdist(x1, x2, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(data_train, shuffle=True, batch_size=256)\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=256)\n",
    "optimizer = optim.SGD(pc.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the constructed PC is not necessarily normalized, we construct the integral circuit that will compute the partition function. Note that parameters are shared and therefore there is no additional memory required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.models.functional import integrate\n",
    "pc_pf = integrate(pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we optimize the parameters for 5 epochs by minimizing the negative log-likelohood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch_idx in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch, _ in train_dataloader:\n",
    "        batch = batch.to(device).unsqueeze(dim=-1)  # Add a channel dimension\n",
    "        log_score = pc(batch)\n",
    "        log_pf = pc_pf(batch)     # Compute the partition function\n",
    "        lls = log_score - log_pf  # Compute the log-likelihood\n",
    "        loss = -torch.mean(lls)   # The loss is the negative average log-likelihood\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss * len(batch)\n",
    "        # Clamp the parameters to ensure they are in the intended domain\n",
    "        # This is needed if we do not use any reparametrization to ensure parameters non-negativity\n",
    "        # In our case, clamping is disable becuase we reparameterize via exponentiation (see above)\n",
    "        #for layer in model.inner_layers:\n",
    "        #    layer.clamp_params()\n",
    "    print(f\"Epoch {epoch_idx}: Average NLL: {running_loss / len(data_train):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then evaluate our model on test data by computing the average log-likelihood and bits per dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pc.eval()\n",
    "    log_pf = pc_pf(torch.empty((), device=device))  # Compute the partition function once for testing\n",
    "    test_lls = 0.0\n",
    "    for batch, _ in test_dataloader:\n",
    "        log_score = pc(batch.to(device).unsqueeze(dim=-1))\n",
    "        lls = log_score - log_pf\n",
    "        test_lls += lls.sum().item()\n",
    "    average_ll = test_lls / len(data_test)\n",
    "    bpd = -average_ll / (num_variables * np.log(2.0))\n",
    "    print(f\"Average test LL: {average_ll:.3f}\")\n",
    "    print(f\"Bits per dimension: {bpd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4acbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a9727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import gpytorch\n",
    "\n",
    "# from ..functions import RBFCovariance\n",
    "# from ..settings import trace_mode\n",
    "from gpytorch.kernels import Kernel\n",
    "\n",
    "\n",
    "def postprocess_rbf(dist_mat):\n",
    "    return dist_mat.div_(-2).exp_()\n",
    "\n",
    "\n",
    "class TestRBFKernel(Kernel):\n",
    "    r\"\"\"\n",
    "    Computes a covariance matrix based on the RBF (squared exponential) kernel\n",
    "    between inputs :math:`\\mathbf{x_1}` and :math:`\\mathbf{x_2}`:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "       \\begin{equation*}\n",
    "          k_{\\text{RBF}}(\\mathbf{x_1}, \\mathbf{x_2}) = \\exp \\left( -\\frac{1}{2}\n",
    "          (\\mathbf{x_1} - \\mathbf{x_2})^\\top \\Theta^{-2} (\\mathbf{x_1} - \\mathbf{x_2}) \\right)\n",
    "       \\end{equation*}\n",
    "\n",
    "    where :math:`\\Theta` is a :attr:`lengthscale` parameter.\n",
    "    See :class:`gpytorch.kernels.Kernel` for descriptions of the lengthscale options.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        This kernel does not have an `outputscale` parameter. To add a scaling parameter,\n",
    "        decorate this kernel with a :class:`gpytorch.kernels.ScaleKernel`.\n",
    "\n",
    "    Args:\n",
    "        :attr:`ard_num_dims` (int, optional):\n",
    "            Set this if you want a separate lengthscale for each\n",
    "            input dimension. It should be `d` if :attr:`x1` is a `n x d` matrix. Default: `None`\n",
    "        :attr:`batch_shape` (torch.Size, optional):\n",
    "            Set this if you want a separate lengthscale for each\n",
    "            batch of input data. It should be `b` if :attr:`x1` is a `b x n x d` tensor. Default: `torch.Size([])`.\n",
    "        :attr:`active_dims` (tuple of ints, optional):\n",
    "            Set this if you want to compute the covariance of only a few input dimensions. The ints\n",
    "            corresponds to the indices of the dimensions. Default: `None`.\n",
    "        :attr:`lengthscale_prior` (Prior, optional):\n",
    "            Set this if you want to apply a prior to the lengthscale parameter.  Default: `None`.\n",
    "        :attr:`lengthscale_constraint` (Constraint, optional):\n",
    "            Set this if you want to apply a constraint to the lengthscale parameter. Default: `Positive`.\n",
    "        :attr:`eps` (float):\n",
    "            The minimum value that the lengthscale can take (prevents divide by zero errors). Default: `1e-6`.\n",
    "\n",
    "    Attributes:\n",
    "        :attr:`lengthscale` (Tensor):\n",
    "            The lengthscale parameter. Size/shape of parameter depends on the\n",
    "            :attr:`ard_num_dims` and :attr:`batch_shape` arguments.\n",
    "\n",
    "    Example:\n",
    "        >>> x = torch.randn(10, 5)\n",
    "        >>> # Non-batch: Simple option\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        >>> # Non-batch: ARD (different lengthscale for each input dimension)\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=5))\n",
    "        >>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n",
    "        >>>\n",
    "        >>> batch_x = torch.randn(2, 10, 5)\n",
    "        >>> # Batch: Simple option\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        >>> # Batch: different lengthscale for each batch\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(batch_shape=torch.Size([2])))\n",
    "        >>> covar = covar_module(x)  # Output: LazyTensor of size (2 x 10 x 10)\n",
    "    \"\"\"\n",
    "\n",
    "    has_lengthscale = True\n",
    "\n",
    "    def forward(self, x1, x2, diag=False, **params):\n",
    "\n",
    "        x1_ = x1.div(self.lengthscale)\n",
    "        x2_ = x2.div(self.lengthscale)\n",
    "        \n",
    "        # print (\"x1, x2\", x1_, x2_)\n",
    "        \n",
    "        return self.covar_dist(\n",
    "            x1_, x2_, square_dist=True, diag=diag, dist_postprocess_func=postprocess_rbf, postprocess=True, **params\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernel = TestRBFKernel()\n",
    "test_kernel.lengthscale = torch.tensor(3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0114f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernel.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4731298",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernel(x1.squeeze(),x2.squeeze()).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8887c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2c61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef03dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5028f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cirkit1",
   "language": "python",
   "name": "cirkit1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
