{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate a PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:00.305482Z",
     "start_time": "2024-03-14T14:35:59.231534Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:01.996183Z",
     "start_time": "2024-03-14T14:36:01.950399Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")  # The device to use, e.g., \"cpu\", \"cuda\", \"cuda:1\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:03.245505Z",
     "start_time": "2024-03-14T14:36:03.190582Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:05.899377Z",
     "start_time": "2024-03-14T14:36:05.858609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb8a072b8f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(4)\n",
    "np.random.seed(4)\n",
    "torch.manual_seed(4)\n",
    "# if 'cuda' in device.type:\n",
    "#     torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and test splits of MNIST, and preprocess them by flattening the tensor images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b879cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from uci_datasets import Dataset\n",
    "\n",
    "from ignite.engine import Events, Engine\n",
    "from ignite.metrics import Average, Loss\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.mlls import VariationalELBO\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baaefe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kin40k dataset, N=40000, d=8\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(\"kin40k\")\n",
    "x_train, y_train, x_test, y_test = data.get_split(split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8905bdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36000, 8), (4000, 8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d1accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_real = x_train[:32000] #32000 # 2053   36584    36584     39063   13281    2672   # RE-RUN # 13279   # 1279   4701  824\n",
    "y_train_real = y_train[:32000]\n",
    "y_train_real = y_train_real.squeeze()\n",
    "x_val = x_train[32000:]\n",
    "y_val = y_train[32000:]\n",
    "y_val = y_val.squeeze()\n",
    "y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84cc07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x_train_real.mean(axis=0)\n",
    "std = x_train_real.std(axis=0)\n",
    "\n",
    "x_train_real_normalized = (x_train_real - mean) / std\n",
    "x_val_normalized = (x_val - mean) / std\n",
    "x_test_normalized = (x_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "41ddfd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dff8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cirkit.models.smgp import initialize_from_data\n",
    "from cirkit.layers.input.sm_layer_imag import SMKernelPosImagLayer, SMKernelNegImagLayer, SMKernelImagLayerParams, SMKernelImagFlattenLayerParams\n",
    "from cirkit.models.smgp import CircuitSMGP\n",
    "from cirkit.models.gp import CircuitGP, initial_values\n",
    "\n",
    "params_module = SMKernelImagLayerParams(num_vars=8, num_output_units=10)\n",
    "# params_module = SMKernelImagFlattenLayerParams(num_vars=8, num_output_units=30)\n",
    "# initialize_from_data(params_module, torch.tensor(x_train_real), torch.tensor(y_train_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd3a338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.region_graph.poon_domingos import PoonDomingos\n",
    "from cirkit.region_graph.random_binary_tree import RandomBinaryTree\n",
    "from cirkit.region_graph.fully_factorized import FullyFactorized\n",
    "from cirkit.region_graph.quad_tree import QuadTree\n",
    "# region_graph = QuadTree(width, height, struct_decomp=False)\n",
    "region_graph = RandomBinaryTree(num_vars=8, depth=3, num_repetitions=4)\n",
    "# region_graph = FullyFactorized(num_vars=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67dce04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.exp_family import CategoricalLayer\n",
    "from cirkit.layers.sum_product import CPLayer\n",
    "from cirkit.layers.input.rbf_kernel import RBFKernelLayer\n",
    "\n",
    "efamily_cls = params_module \n",
    "efamily_kwargs = {}\n",
    "layer_cls = CPLayer\n",
    "layer_kwargs = {'rank': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3735e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorizedSMPC(\n",
      "  (input_layer_params): SMKernelImagLayerParams(\n",
      "    (params_sigma): ReparamExp()\n",
      "    (params_mu): ReparamIdentity()\n",
      "    (params_weight): ReparamSoftmax()\n",
      "  )\n",
      "  (input_layer_pos): SMKernelPosImagLayer(\n",
      "    (params): SMKernelImagLayerParams(\n",
      "      (params_sigma): ReparamExp()\n",
      "      (params_mu): ReparamIdentity()\n",
      "      (params_weight): ReparamSoftmax()\n",
      "    )\n",
      "  )\n",
      "  (input_layer_neg): SMKernelNegImagLayer(\n",
      "    (params): SMKernelImagLayerParams(\n",
      "      (params_sigma): ReparamExp()\n",
      "      (params_mu): ReparamIdentity()\n",
      "      (params_weight): ReparamSoftmax()\n",
      "    )\n",
      "  )\n",
      "  (scope_layer): ScopeLayer()\n",
      "  (inner_layers): ModuleList(\n",
      "    (0-2): 3 x CollapsedCPLayer(\n",
      "      (params_in): ReparamExp()\n",
      "    )\n",
      "    (3): SumLayer(\n",
      "      (params): ReparamExp()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from cirkit.reparams.leaf import ReparamExp, ReparamLogSoftmax, ReparamSoftmax\n",
    "from cirkit.models.tensorized_circuit import TensorizedPC\n",
    "from cirkit.models.tensorized_SM_circuit import TensorizedSMPC\n",
    "pc_sm = TensorizedSMPC.from_region_graph(\n",
    "    region_graph,\n",
    "    num_inner_units=10,\n",
    "    num_input_units=10,\n",
    "    efamily_cls=efamily_cls,\n",
    "    efamily_kwargs=efamily_kwargs,\n",
    "    layer_cls=layer_cls,\n",
    "    layer_kwargs=layer_kwargs,\n",
    "    num_classes=1,\n",
    "    reparam=ReparamExp # ReparamLogSoftmax # ReparamExp ReparamSoftmax\n",
    ")\n",
    "pc_sm.to(device)\n",
    "print(pc_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a72572dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 8])\n",
      "torch.Size([10, 1, 8])\n",
      "torch.Size([8, 10, 10])\n",
      "torch.Size([16, 10, 10])\n",
      "torch.Size([8, 10, 10])\n",
      "torch.Size([4, 10, 1])\n",
      "torch.Size([1, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "for param in pc_sm.parameters(): \n",
    "    print (param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04a58de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class IdentityMapping(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentityMapping, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7d527e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 32000 datapoints for 50 epochs\n",
      "f_X_samples shape torch.Size([1000, 8])\n",
      "initial_lengthscale tensor(3.8970)\n",
      "All circuit parameters shape: \n",
      "torch.Size([10, 1, 8])\n",
      "torch.Size([10, 1, 8])\n",
      "torch.Size([8, 10, 10])\n",
      "torch.Size([16, 10, 10])\n",
      "torch.Size([8, 10, 10])\n",
      "torch.Size([4, 10, 1])\n",
      "torch.Size([1, 4, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irwinchay/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "/Users/irwinchay/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Users/irwinchay/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/contrib/handlers/tqdm_logger.py:126: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(24)\n",
    "torch.manual_seed(24) ####################### CHANGE\n",
    "\n",
    "batch_size = 32 # 64\n",
    "\n",
    "ds_train = torch.utils.data.TensorDataset(torch.from_numpy(x_train_real_normalized).float(), torch.from_numpy(y_train_real).float())\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, drop_last=True) # suffle \n",
    "\n",
    "ds_val = torch.utils.data.TensorDataset(torch.from_numpy(x_val_normalized).float(), torch.from_numpy(y_val).float())\n",
    "dl_val = torch.utils.data.DataLoader(ds_val, batch_size=512, shuffle=False)\n",
    "\n",
    "ds_test = torch.utils.data.TensorDataset(torch.from_numpy(x_test_normalized).float(), torch.from_numpy(y_test).float())\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=512, shuffle=False)\n",
    "\n",
    "# steps = 5e3\n",
    "epochs = 50\n",
    "print(f\"Training with {len(x_train_real)} datapoints for {epochs} epochs\")\n",
    "\n",
    "# Change this boolean to False for SNGP\n",
    "DUE = True\n",
    "\n",
    "input_dim = 8 # input di  # 128\n",
    "num_outputs = 1 # regression with 1D output\n",
    "\n",
    "feature_extractor = IdentityMapping()\n",
    "\n",
    "\n",
    "n_inducing_points = 50 # 100\n",
    " \n",
    "initial_inducing_points, initial_lengthscale = initial_values(\n",
    "    ds_train, feature_extractor, n_inducing_points)\n",
    "\n",
    "gp_model = CircuitSMGP(\n",
    "        num_outputs=num_outputs,\n",
    "        num_features=input_dim,          # CHANGE features / input_dim\n",
    "        initial_inducing_points=initial_inducing_points,\n",
    "        circuit=pc_sm,\n",
    "    )\n",
    "\n",
    "likelihood = GaussianLikelihood()\n",
    "elbo_fn = VariationalELBO(likelihood, gp_model, num_data=len(ds_train))\n",
    "loss_fn = lambda x, y: -elbo_fn(x, y)\n",
    "    \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gp_model = gp_model.cuda()\n",
    "    likelihood = likelihood.cuda()\n",
    "\n",
    "# learning rate   \n",
    "lr = 1e-3\n",
    "\n",
    "parameters = [\n",
    "    {\"params\": gp_model.parameters(), \"lr\": lr},\n",
    "]\n",
    "\n",
    "parameters.append({\"params\": likelihood.parameters(), \"lr\": lr})\n",
    "    \n",
    "optimizer = torch.optim.Adam(parameters)\n",
    "pbar = ProgressBar()\n",
    "\n",
    "def step(engine, batch):\n",
    "    gp_model.train()\n",
    "    likelihood.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x, y = batch\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    y_pred = gp_model(x) # get y\n",
    "\n",
    "\n",
    "    loss = loss_fn(y_pred, y) # loss\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    gp_model.eval() # set to eval\n",
    "    likelihood.eval()\n",
    "    \n",
    "    x, y = batch\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    y_pred = gp_model(x)    \n",
    "    return y_pred, y\n",
    "\n",
    "    \n",
    "trainer = Engine(step)\n",
    "evaluator = Engine(eval_step)\n",
    "\n",
    "metric = Average()\n",
    "metric.attach(trainer, \"loss\")\n",
    "pbar.attach(trainer)\n",
    "\n",
    "metric = Loss(lambda y_pred, y: - likelihood.expected_log_prob(y, y_pred).mean())\n",
    "metric.attach(evaluator, \"loss\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=int(epochs/20) + 1))\n",
    "def log_results(trainer):\n",
    "    evaluator.run(dl_val) # val dataset\n",
    "    print(f\"Results - Epoch: {trainer.state.epoch} - \"\n",
    "          f\"Val Loss: {evaluator.state.metrics['loss']:.2f} - \"\n",
    "          f\"Train Loss: {trainer.state.metrics['loss']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7cab3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 8])\n",
      "torch.Size([50])\n",
      "torch.Size([50, 50])\n",
      "torch.Size([10, 1, 8])\n",
      "torch.Size([10, 1, 8])\n",
      "torch.Size([8, 10, 10])\n",
      "torch.Size([16, 10, 10])\n",
      "torch.Size([8, 10, 10])\n",
      "torch.Size([4, 10, 1])\n",
      "torch.Size([1, 4, 1])\n",
      "torch.Size([1])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for index, param in enumerate(gp_model.parameters()): \n",
    "    # if (index==2):\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82340f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irwinchay/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:130: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2198.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c62744646146879207c339ce0f76fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d20f20e4be4439f90f997f01a1d1baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d099a1bed51d42e4a4ae874e95f5abe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 3 - Val Loss: 131115.28 - Train Loss: 197295.81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f34bbfdf804208aefdf3a8ec425c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505e3f8bdd8e49618671eac887c26dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c01167125e4f4bb1cac003b13b4b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 6 - Val Loss: 21793.44 - Train Loss: 29002.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07cf46fcfee4800a9157e894a9cf2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf335eb1603b45a5b1bc9b5207bff6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10df55ec5a8f4e378f16692fddb0eb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 9 - Val Loss: 4594.61 - Train Loss: 5991.33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dad17d3a5254ab5a547ff7c53f67543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1f44f09bf1423c91871a62ffea845c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603d96ae37e64a0c8154845e2383ed80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 12 - Val Loss: 8.87 - Train Loss: 13.58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e79d3f932c42a286b453c7636303a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d15ba98bfe45018dc0654d0885c5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f920f52e03e347c6992d3867ab7d7e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 15 - Val Loss: 2.28 - Train Loss: 2.62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2f35fd69024b45bf7c97a42c817b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b7fab39fa04cc08180f64e3c1875ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irwinchay/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py:259: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9282b66d2db84760a51d31f88df1384e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:898\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:941\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 941\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:999\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 999\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:965\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 965\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    967\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:1074\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "Cell \u001b[0;32mIn[19], line 72\u001b[0m, in \u001b[0;36mstep\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     69\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     70\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 72\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mgp_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# get y\u001b[39;00m\n\u001b[1;32m     75\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y) \u001b[38;5;66;03m# loss\u001b[39;00m\n\u001b[1;32m     77\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/models/approximate_gp.py:81\u001b[0m, in \u001b[0;36mApproximateGP.__call__\u001b[0;34m(self, inputs, prior, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     80\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariational_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/variational/variational_strategy.py:169\u001b[0m, in \u001b[0;36mVariationalStrategy.__call__\u001b[0;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# Mark that we have updated the variational strategy\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdated_strategy\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/variational/_variational_strategy.py:124\u001b[0m, in \u001b[0;36m_VariationalStrategy.__call__\u001b[0;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Get q(f)\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(variational_dist_u, MultivariateNormal):\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43minducing_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43minducing_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariational_dist_u\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariational_inducing_covar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariational_dist_u\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_covariance_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(variational_dist_u, Delta):\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    133\u001b[0m         x, inducing_points, inducing_values\u001b[38;5;241m=\u001b[39mvariational_dist_u\u001b[38;5;241m.\u001b[39mmean, variational_inducing_covar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    134\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/module.py:30\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 30\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/variational/variational_strategy.py:96\u001b[0m, in \u001b[0;36mVariationalStrategy.forward\u001b[0;34m(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m num_induc \u001b[38;5;241m=\u001b[39m inducing_points\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     95\u001b[0m test_mean \u001b[38;5;241m=\u001b[39m full_output\u001b[38;5;241m.\u001b[39mmean[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, num_induc:]\n\u001b[0;32m---> 96\u001b[0m induc_induc_covar \u001b[38;5;241m=\u001b[39m \u001b[43mfull_covar\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_induc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_induc\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_jitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m induc_data_covar \u001b[38;5;241m=\u001b[39m full_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :num_induc, num_induc:]\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     98\u001b[0m data_data_covar \u001b[38;5;241m=\u001b[39m full_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, num_induc:, num_induc:]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:277\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.add_jitter\u001b[0;34m(self, jitter_val)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_jitter\u001b[39m(\u001b[38;5;28mself\u001b[39m, jitter_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_jitter(jitter_val)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:332\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m     temp_active_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m temp_active_dims\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/kernels/kernel.py:402\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    400\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m     res \u001b[38;5;241m=\u001b[39m lazify(\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/module.py:30\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 30\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/gpytorch/kernels/scale_kernel.py:103\u001b[0m, in \u001b[0;36mScaleKernel.forward\u001b[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2, last_dim_is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m--> 103\u001b[0m     orig_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     outputscales \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputscale\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_dim_is_batch:\n",
      "File \u001b[0;32m~/Downloads/cirkit_kernel/cirkit/models/sm_kernel.py:35\u001b[0m, in \u001b[0;36mSMCircuitKernel.forward\u001b[0;34m(self, x1, x2, **params)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcircuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/cirkit_kernel/cirkit/models/tensorized_SM_circuit.py:306\u001b[0m, in \u001b[0;36mTensorizedSMPC.__call__\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1: Tensor, x2: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    297\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Invoke the forward function.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m        Tensor: The output of the circuit, shape (*B, K).\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/cirkit_kernel/cirkit/models/tensorized_SM_circuit.py:352\u001b[0m, in \u001b[0;36mTensorizedSMPC.forward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    349\u001b[0m x_neg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope_layer(x_neg)  \u001b[38;5;66;03m# shape (F, K, *B)\u001b[39;00m\n\u001b[1;32m    351\u001b[0m log_output_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_layers(x_pos)\u001b[38;5;241m.\u001b[39mmovedim(source\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, destination\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# shape (K, *B) -> (*B, K)\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m log_output_neg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_neg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmovedim(source\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, destination\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# shape (K, *B) -> (*B, K)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m combined_output \u001b[38;5;241m=\u001b[39m ((torch\u001b[38;5;241m.\u001b[39mexp(log_output_pos) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(log_output_neg)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mreal\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m combined_output\n",
      "File \u001b[0;32m~/Downloads/cirkit_kernel/cirkit/models/tensorized_SM_circuit.py:331\u001b[0m, in \u001b[0;36mTensorizedSMPC._eval_layers\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# fold_idx shape (F, H)\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs[fold_idx]  \u001b[38;5;66;03m# shape (F, H, K, *B)\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape (F, K, *B)\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     layer_outputs\u001b[38;5;241m.\u001b[39mappend(outputs)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/cirkit_kernel/cirkit/layers/layer.py:86\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, x, *_)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, \u001b[38;5;241m*\u001b[39m_: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Invoke the forward function.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m        Tensor: The output of this layer, shape (F, K, *B).\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/cirkit_kernel/cirkit/layers/sum_product/cp.py:173\u001b[0m, in \u001b[0;36mBaseCPLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    171\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_reduce_log(x)  \u001b[38;5;66;03m# shape (F, K, *B)\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlog_func_exp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_in_linear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape (F, K, *B)\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     x \u001b[38;5;241m=\u001b[39m log_func_exp(\n\u001b[1;32m    178\u001b[0m         x, func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_out_linear, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     )  \u001b[38;5;66;03m# shape (F, K, *B)\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/cirkit_kernel/cirkit/utils/log_trick.py:54\u001b[0m, in \u001b[0;36mlog_func_exp\u001b[0;34m(func, dim, keepdim, *x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keepdim:\n\u001b[1;32m     52\u001b[0m     sum_max_x \u001b[38;5;241m=\u001b[39m sum_max_x\u001b[38;5;241m.\u001b[39msqueeze(dim)\n\u001b[0;32m---> 54\u001b[0m log_func_exp_x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_exp_x\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m sum_max_x\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_func_exp_x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run(dl_train, max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537363e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in likelihood.parameters(): \n",
    "    print (param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c666fe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.28\n"
     ]
    }
   ],
   "source": [
    "from ignite.metrics import RootMeanSquaredError\n",
    "import torch\n",
    "\n",
    "# Assuming you have a function to compute RMSE, or you're using Ignite's RMSE metric\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    gp_model.eval()  # Ensure model is in evaluation mode\n",
    "    likelihood.eval()\n",
    "    \n",
    "    x, y = batch\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    # Assuming your model outputs a distribution, e.g., MultivariateNormal\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        distribution = gp_model(x)\n",
    "        y_pred = distribution.mean  # Use the mean of the distribution as the prediction\n",
    "\n",
    "    return y_pred, y\n",
    "\n",
    "# Update the evaluator engine\n",
    "evaluator = Engine(eval_step)\n",
    "\n",
    "# Attach the RMSE metric to the evaluator\n",
    "rmse = RootMeanSquaredError()\n",
    "rmse.attach(evaluator, \"RMSE\")\n",
    "\n",
    "# After training, run the evaluator on the test dataset to compute the RMSE\n",
    "evaluator.run(dl_test)\n",
    "\n",
    "# Retrieve and display the RMSE\n",
    "test_rmse = evaluator.state.metrics['RMSE']\n",
    "print(f\"Test RMSE: {test_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b5f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5143d70",
   "metadata": {},
   "source": [
    "# Test SM circuit kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c4f37439",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = torch.rand((3, 8 ,1))\n",
    "x_2 = torch.rand((3, 8 ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4c0ef41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1, 8]), torch.Size([4, 1, 8]), torch.Size([1, 4, 1]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_sm.input_layer_params.params_mu().shape, pc_sm.input_layer_params.params_sigma().shape, pc_sm.inner_layers[0].params_in().shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9e3a4a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.2293e-04],\n",
       "         [2.1714e-02],\n",
       "         [3.4552e-07]],\n",
       "\n",
       "        [[2.1888e-09],\n",
       "         [6.2656e-13],\n",
       "         [1.0155e-09]],\n",
       "\n",
       "        [[6.2082e-07],\n",
       "         [3.9243e-08],\n",
       "         [3.3809e-10]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_sm(x_1, x_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2da1d7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "tensor(0.0217, grad_fn=<AddBackward0>)\n",
      "tensor(3.4552e-07, grad_fn=<AddBackward0>)\n",
      "tensor(2.1888e-09, grad_fn=<AddBackward0>)\n",
      "tensor(6.2656e-13, grad_fn=<AddBackward0>)\n",
      "tensor(1.0155e-09, grad_fn=<AddBackward0>)\n",
      "tensor(6.2082e-07, grad_fn=<AddBackward0>)\n",
      "tensor(3.9243e-08, grad_fn=<AddBackward0>)\n",
      "tensor(3.3809e-10, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sigma = pc_sm.input_layer_params.params_sigma().squeeze(1)\n",
    "mu = pc_sm.input_layer_params.params_mu().squeeze(1)\n",
    "weights = pc_sm.inner_layers[0].params_in().squeeze(0, 2)\n",
    "\n",
    "def SMK(x1, x2, sigma, mu): \n",
    "    tau = x1-x2\n",
    "    return torch.prod(torch.exp(-2*(torch.pi**2)* (tau**2)*(sigma**2) )) * torch.cos(2.0*torch.pi*torch.dot(tau,mu))\n",
    "\n",
    "for i in range(x_1.shape[0]): \n",
    "    for j in range(x_2.shape[0]): \n",
    "        smk = []\n",
    "        for k in range(sigma.shape[0]): \n",
    "            smk.append(weights[k] * SMK(x_1.squeeze(-1)[i], x_2.squeeze(-1)[j], sigma[k], mu[k]) )\n",
    "        print(sum(smk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37ce73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c2c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fb408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed631b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SM kernel Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d906bdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1328e-08, -7.2096e-08, -1.0445e-33],\n",
       "        [ 1.4426e-23,  4.1552e-24, -4.1187e-12],\n",
       "        [-2.6234e-14, -1.5526e-17,  1.7630e-19]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from cirkit.layers.input.sm_layer_imag import SMKernelPosImagLayer, SMKernelNegImagLayer, SMKernelImagLayerParams\n",
    "# (3,5,1)\n",
    "x_1 = torch.rand((3, 7, 1))\n",
    "x_2 = torch.rand((3, 7, 1))\n",
    "\n",
    "params_module = SMKernelImagLayerParams(num_vars=7, num_output_units=12)\n",
    "pos_layer = SMKernelPosImagLayer(num_vars=7, num_output_units=12, params_module=params_module)\n",
    "neg_layer = SMKernelNegImagLayer(num_vars=7, num_output_units=12, params_module=params_module)\n",
    "\n",
    "torch.mean(((torch.prod(torch.exp(pos_layer(x_1, x_2)), dim=2) + torch.prod(torch.exp(neg_layer(x_1, x_2)), dim=2) )*0.5), dim=2).squeeze().real\n",
    "\n",
    "# 1/2/3/4/5\n",
    "# 1/2/4/8/16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3c13f66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do leaf1 and leaf2 share the same 'shared_linear' parameters?  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Do leaf1 and leaf2 share the same 'shared_linear' parameters? \", \n",
    "      id(pos_layer.params.params_sigma()) == id(neg_layer.params.params_sigma() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1d81e9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1])\n",
      "torch.Size([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for param in pos_layer.parameters(): \n",
    "    print (param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7627187d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 7])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_layer.params.params_sigma().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "66d1c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.1328e-08, grad_fn=<DivBackward0>)\n",
      "tensor(-7.2096e-08, grad_fn=<DivBackward0>)\n",
      "tensor(-1.0445e-33, grad_fn=<DivBackward0>)\n",
      "tensor(1.4425e-23, grad_fn=<DivBackward0>)\n",
      "tensor(4.1552e-24, grad_fn=<DivBackward0>)\n",
      "tensor(-4.1187e-12, grad_fn=<DivBackward0>)\n",
      "tensor(-2.6234e-14, grad_fn=<DivBackward0>)\n",
      "tensor(-1.5526e-17, grad_fn=<DivBackward0>)\n",
      "tensor(1.7630e-19, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sigma = pos_layer.params.params_sigma().squeeze(1)\n",
    "mu = pos_layer.params.params_mu().squeeze(1)\n",
    "\n",
    "def SMK(x1, x2, sigma, mu): \n",
    "    tau = x1-x2\n",
    "    return torch.prod(torch.exp(-2*(torch.pi**2)* (tau**2)*(sigma**2) )) * torch.cos(2*torch.pi*torch.dot(tau,mu))\n",
    "\n",
    "for i in range(x_1.shape[0]): \n",
    "    for j in range(x_2.shape[0]): \n",
    "        smk = []\n",
    "        for k in range(sigma.shape[0]): \n",
    "            smk.append(SMK(x_1[i].squeeze(-1), x_2[j].squeeze(-1), sigma[k], mu[k]) )\n",
    "        print(sum(smk) / len(smk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "1ff60d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.region_graph.quad_tree import QuadTree\n",
    "# region_graph = QuadTree(width, height, struct_decomp=False)\n",
    "# region_graph = RandomBinaryTree(num_vars=128, depth=6, num_repetitions=1)\n",
    "region_graph = FullyFactorized(num_vars=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "8a7f43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.exp_family import CategoricalLayer\n",
    "from cirkit.layers.sum_product import CPLayer\n",
    "from cirkit.layers.input.rbf_kernel import RBFKernelLayer\n",
    "\n",
    "efamily_cls = params_module\n",
    "efamily_kwargs = {}\n",
    "layer_cls = CPLayer\n",
    "layer_kwargs = {'rank': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "a4ca5fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorizedSMPC(\n",
      "  (input_layer_params): SMKernelImagLayerParams(\n",
      "    (params_sigma): ReparamExp()\n",
      "    (params_mu): ReparamIdentity()\n",
      "  )\n",
      "  (input_layer_pos): SMKernelPosImagLayer(\n",
      "    (params): SMKernelImagLayerParams(\n",
      "      (params_sigma): ReparamExp()\n",
      "      (params_mu): ReparamIdentity()\n",
      "    )\n",
      "  )\n",
      "  (input_layer_neg): SMKernelNegImagLayer(\n",
      "    (params): SMKernelImagLayerParams(\n",
      "      (params_sigma): ReparamExp()\n",
      "      (params_mu): ReparamIdentity()\n",
      "    )\n",
      "  )\n",
      "  (scope_layer): ScopeLayer()\n",
      "  (inner_layers): ModuleList(\n",
      "    (0): CollapsedCPLayer(\n",
      "      (params_in): ReparamSoftmax()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from cirkit.reparams.leaf import ReparamExp, ReparamLogSoftmax, ReparamSoftmax\n",
    "from cirkit.models.tensorized_circuit import TensorizedPC\n",
    "from cirkit.models.tensorized_SM_circuit import TensorizedSMPC\n",
    "pc_sm = TensorizedSMPC.from_region_graph(\n",
    "    region_graph,\n",
    "    num_inner_units=12,\n",
    "    num_input_units=12,\n",
    "    efamily_cls=efamily_cls,\n",
    "    efamily_kwargs=efamily_kwargs,\n",
    "    layer_cls=layer_cls,\n",
    "    layer_kwargs=layer_kwargs,\n",
    "    num_classes=1,\n",
    "    reparam=ReparamSoftmax # ReparamLogSoftmax # ReparamExp\n",
    ")\n",
    "pc_sm.to(device)\n",
    "print(pc_sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f7428d75",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[322], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pc_sm\u001b[38;5;241m.\u001b[39minner_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mparams_in\u001b[38;5;241m.\u001b[39mparam \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m1\u001b[39m))))\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpc_sm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/cirkit_kernel/cirkit/reparams/reparam.py:79\u001b[0m, in \u001b[0;36mReparameterization.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the reparameterized params.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m        Tensor: The params after reparameterizaion.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/cirkit_kernel/cirkit/reparams/leaf.py:192\u001b[0m, in \u001b[0;36mReparamSoftmax.forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_mask\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# torch.softmax can only accept one dim\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unflatten_dims(torch\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flatten_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# nan will appear when the only 1 element is masked. fill nan as 1 (0 in log-sapce)\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# +inf and -inf will not appear\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnan_to_num(param, nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/cirkit_kernel/cirkit/reparams/reparam.py:108\u001b[0m, in \u001b[0;36mReparameterization._flatten_dims\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m perm \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)) \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims)\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# TODO: consider torch.movedim?\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# flatten end_dim is inclusive\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten(\n\u001b[1;32m    109\u001b[0m     start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[\u001b[38;5;241m0\u001b[39m], end_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    110\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4"
     ]
    }
   ],
   "source": [
    "# pc_sm.inner_layers[0].params_in.param = torch.nn.Parameter(torch.log(torch.ones((1, 12, 1))))\n",
    "\n",
    "# pc_sm.inner_layers[0].params_in()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "54c145d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 7])\n",
      "torch.Size([12, 1, 7])\n",
      "torch.Size([1, 7, 12, 1])\n"
     ]
    }
   ],
   "source": [
    "for param in pc_sm.parameters(): \n",
    "    print (param.shape)\n",
    "    # print (param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c91f67fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 1])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_sm(x_1, x_2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b2f9d8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-13.2346+2.7592j,  -0.0169-0.0985j, -11.9529+2.6222j],\n",
       "         [ -0.6093+0.5920j,  -8.9233-2.2656j,  -0.3599+0.4550j],\n",
       "         [ -0.6418+0.6076j,  -8.8009-2.2500j,  -0.3850+0.4706j]],\n",
       "        grad_fn=<SqueezeBackward0>),\n",
       " tensor([[-13.2346-2.7592j,  -0.0169+0.0985j, -11.9529-2.6222j],\n",
       "         [ -0.6093-0.5920j,  -8.9233+2.2656j,  -0.3599-0.4550j],\n",
       "         [ -0.6418-0.6076j,  -8.8009+2.2500j,  -0.3850-0.4706j]],\n",
       "        grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_layer(x_1, x_2).squeeze(), neg_layer(x_1, x_2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0798ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Spectral Mixture (SM) kernel function correctly\n",
    "def sm_kernel(w, tau, mu, variance):\n",
    "    \"\"\"\n",
    "    Compute the Spectral Mixture (SM) kernel given weights w, time points tau,\n",
    "    mixture means mu, and variance parameters.\n",
    "\n",
    "    :param w: Weight for each mixture component (Q-dimensional tensor).\n",
    "    :param tau: The time difference tensor (1-dimensional tensor representing time differences).\n",
    "    :param mu: The mean for each mixture component (Q-dimensional tensor).\n",
    "    :param variance: The variance for each mixture component (Q-dimensional tensor).\n",
    "    :return: The computed SM kernel as a 1D tensor.\n",
    "    \"\"\"\n",
    "    Q = w.size(0)  # Number of mixture components\n",
    "    tau_expanded = tau.unsqueeze(-1)  # Expand dims to allow for broadcasting with Q components\n",
    "\n",
    "    # Compute the cosine part of the kernel\n",
    "    cosine_part = torch.cos(2 * torch.pi * tau_expanded * mu)\n",
    "\n",
    "    # Compute the exponential part of the kernel\n",
    "    exp_part = torch.exp(-2 * torch.pi**2 * tau_expanded.pow(2) * variance)\n",
    "\n",
    "    # Combine the parts and sum over the mixture components to get the kernel value\n",
    "    kernel_values = torch.sum(w * cosine_part * exp_part, dim=1)\n",
    "\n",
    "    return kernel_values\n",
    "\n",
    "# Example tensors for the parameters\n",
    "# Assuming Q mixture components\n",
    "Q = 3  # Example values for the number of mixtures\n",
    "w_example = torch.rand(Q)  # Example weights tensor\n",
    "tau_example = torch.rand(10)  # Example time difference tensor with 10 samples\n",
    "mu_example = torch.rand(Q)  # Example means tensor\n",
    "variance_example = torch.rand(Q)  # Example variance tensor\n",
    "\n",
    "# Call the SM kernel function\n",
    "kernel_output = sm_kernel(w_example, tau_example, mu_example, variance_example)\n",
    "kernel_output\n",
    "\n",
    "\n",
    "# Random example inputs for demonstration purposes\n",
    "# tau_example = (x_1[0].squeeze() - x_2[0].squeeze()).unsqueeze(0)     # Example tau tensor\n",
    "# mu_example = pos_layer.params.params_mu().squeeze(-2)       # Example mu tensor\n",
    "# sigma_example = pos_layer.params.params_sigma().squeeze(-2)    # Example sigma tensor\n",
    "# weight_example = torch.tensor([1])      # Example weight tensor\n",
    "\n",
    "# # Calculate the SM kernel\n",
    "# sm_kernel_example = sm_kernel(tau_example, mu_example, sigma_example, weight_example)\n",
    "# sm_kernel_example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:25.724719Z",
     "start_time": "2024-03-14T14:36:25.680948Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_1[0].squeeze() - x_2[1].squeeze()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:35:35.437628Z",
     "start_time": "2024-03-14T14:35:35.393853Z"
    }
   },
   "outputs": [],
   "source": [
    "pc.scope_layer.scope.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:27.302533Z",
     "start_time": "2024-03-14T14:36:27.260539Z"
    }
   },
   "outputs": [],
   "source": [
    "pc.inner_layers[0].params_in() #.param #.shape #.param.shape\n",
    "# (F, H, I, O)\n",
    "# (fold count, arity, input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:11:52.080085Z",
     "start_time": "2024-03-14T13:11:52.073368Z"
    }
   },
   "outputs": [],
   "source": [
    "from cirkit.models.rbf_kernel import RBFCircuitKernel\n",
    "\n",
    "circuit_kernel = RBFCircuitKernel(pc, batch_shape=torch.Size([]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:06:06.337943Z",
     "start_time": "2024-03-14T13:06:06.330408Z"
    }
   },
   "outputs": [],
   "source": [
    "circuit_kernel(x1.squeeze(), x2.squeeze()).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:06:07.504758Z",
     "start_time": "2024-03-14T13:06:07.498492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 7, 4, 1])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:06:09.102855Z",
     "start_time": "2024-03-14T13:06:09.096848Z"
    }
   },
   "outputs": [],
   "source": [
    "scope_tensor = torch.tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]],\n",
    "\n",
    "        [[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]],\n",
    "\n",
    "        [[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]],\n",
    "\n",
    "        [[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]],\n",
    "\n",
    "        [[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]],\n",
    "\n",
    "        [[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]],\n",
    "\n",
    "        [[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]]])\n",
    "\n",
    "pos_output = pos_layer(x_1, x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.3094e-01-0.4083j, -2.2431e-01-0.2654j, -2.3957e+00-0.8674j],\n",
       "          [-2.6958e+00-0.9201j, -1.9234e+00-0.7772j, -6.0567e+00-1.3792j],\n",
       "          [-1.0286e+01+1.7973j, -1.1987e+01+1.9403j, -5.7027e+00+1.3383j]],\n",
       "\n",
       "         [[-2.4464e+00-0.7322j, -1.0335e+00-0.4759j, -1.1039e+01-1.5553j],\n",
       "          [-1.2422e+01-1.6499j, -8.8623e+00-1.3936j, -2.7907e+01-2.4730j],\n",
       "          [-4.7395e+01-3.0605j, -5.5232e+01-2.8042j, -2.6277e+01+2.3996j]],\n",
       "\n",
       "         [[-1.5411e+00-0.0452j, -6.5107e-01-0.0294j, -6.9536e+00-0.0961j],\n",
       "          [-7.8248e+00-0.1019j, -5.5827e+00-0.0861j, -1.7580e+01-0.1528j],\n",
       "          [        nan+nanj, -3.4793e+01+0.2149j, -1.6553e+01+0.1483j]],\n",
       "\n",
       "         [[-1.6925e+00-0.4124j, -7.1505e-01-0.2681j, -7.6369e+00-0.8761j],\n",
       "          [-8.5938e+00-0.9294j, -6.1313e+00-0.7850j, -1.9308e+01-1.3930j],\n",
       "          [-3.2790e+01+1.8154j, -3.8212e+01+1.9597j, -1.8179e+01+1.3517j]]],\n",
       "\n",
       "\n",
       "        [[[-4.3661e-01-0.3991j, -1.5363e+01-2.3676j, -1.9595e+01-2.6739j],\n",
       "          [-7.2240e+00+1.6235j, -3.2603e-01-0.3449j, -1.1622e+00-0.6512j],\n",
       "          [-7.6894e-01-0.5297j, -1.7103e+01-2.4981j, -2.1555e+01-2.8044j]],\n",
       "\n",
       "         [[-1.2490e+00-0.4441j, -4.3947e+01-2.6342j, -5.6053e+01-2.9750j],\n",
       "          [-2.0665e+01+1.8064j, -9.3265e-01-0.3837j, -3.3247e+00-0.7245j],\n",
       "          [-2.1997e+00-0.5893j, -4.8927e+01-2.7794j, -6.1660e+01-3.1202j]],\n",
       "\n",
       "         [[-1.5873e+00-0.4144j, -5.5850e+01-2.4582j, -7.1236e+01-2.7762j],\n",
       "          [-2.6263e+01+1.6857j, -1.1853e+00-0.3581j, -4.2252e+00-0.6761j],\n",
       "          [        nan+nanj, -6.2179e+01-2.5937j, -7.8361e+01-2.9117j]],\n",
       "\n",
       "         [[-4.4345e-01-0.2912j, -1.5603e+01-1.7273j, -1.9901e+01-1.9507j],\n",
       "          [-7.3371e+00+1.1844j, -3.3114e-01-0.2516j, -1.1804e+00-0.4751j],\n",
       "          [-7.8098e-01-0.3864j, -1.7371e+01-1.8225j, -2.1892e+01-2.0460j]]],\n",
       "\n",
       "\n",
       "        [[[-2.9707e+00+0.3724j, -3.8285e+00-0.4227j, -7.2906e-01+0.1845j],\n",
       "          [-2.9001e+00+0.3679j, -3.9096e+00-0.4272j, -6.9427e-01+0.1800j],\n",
       "          [-2.6452e+01+1.1112j, -2.1401e+00+0.3161j, -1.8262e+01+0.9233j]],\n",
       "\n",
       "         [[-2.0726e+00+0.1821j, -2.6710e+00-0.2067j, -5.0864e-01+0.0902j],\n",
       "          [-2.0233e+00+0.1799j, -2.7276e+00-0.2089j, -4.8437e-01+0.0880j],\n",
       "          [-1.8455e+01+0.5433j, -1.4931e+00+0.1545j, -1.2741e+01+0.4514j]],\n",
       "\n",
       "         [[-1.2360e+01+1.8397j, -1.5929e+01-2.0885j, -3.0334e+00+0.9114j],\n",
       "          [-1.2066e+01+1.8177j, -1.6267e+01-2.1105j, -2.8886e+00+0.8894j],\n",
       "          [       -inf+nanj, -8.9043e+00+1.5615j, -7.5983e+01-1.7218j]],\n",
       "\n",
       "         [[-2.7982e+00+0.7557j, -3.6062e+00-0.8579j, -6.8672e-01+0.3744j],\n",
       "          [-2.7316e+00+0.7467j, -3.6826e+00-0.8670j, -6.5395e-01+0.3653j],\n",
       "          [-2.4916e+01+2.2551j, -2.0158e+00+0.6414j, -1.7202e+01+1.8738j]]],\n",
       "\n",
       "\n",
       "        [[[-3.8262e+00+0.8995j, -1.7693e+01+1.9342j, -4.7185e+00+0.9989j],\n",
       "          [-2.5474e+00-0.7339j, -4.2794e-01+0.3008j, -1.9042e+00-0.6345j],\n",
       "          [-8.1728e-01+0.4157j, -9.9493e+00+1.4505j, -1.2548e+00+0.5151j]],\n",
       "\n",
       "         [[-8.3641e+00+1.6969j, -3.8677e+01-2.6343j, -1.0315e+01+1.8844j],\n",
       "          [-5.5686e+00-1.3846j, -9.3548e-01+0.5675j, -4.1625e+00-1.1971j],\n",
       "          [-1.7866e+00+0.7842j, -2.1749e+01+2.7363j, -2.7430e+00+0.9717j]],\n",
       "\n",
       "         [[-4.3808e+00+1.8448j, -2.0257e+01-2.3161j, -5.4024e+00+2.0487j],\n",
       "          [-2.9166e+00-1.5053j, -4.8997e-01+0.6170j, -2.1802e+00-1.3015j],\n",
       "          [        nan+nanj, -1.1392e+01+2.9749j, -1.4367e+00+1.0565j]],\n",
       "\n",
       "         [[-9.2761e+00+2.1337j, -4.2894e+01-1.6950j, -1.1439e+01+2.3694j],\n",
       "          [-6.1758e+00-1.7410j, -1.0375e+00+0.7136j, -4.6164e+00-1.5052j],\n",
       "          [-1.9814e+00+0.9861j, -2.4121e+01-2.8425j, -3.0421e+00+1.2219j]]],\n",
       "\n",
       "\n",
       "        [[[-4.6458e-01+0.4903j, -1.0743e+01+2.3576j, -3.8066e-01-0.4438j],\n",
       "          [-3.1383e-01+0.4030j, -9.9616e+00+2.2703j, -5.4521e-01-0.5311j],\n",
       "          [-5.3585e+00+1.6651j, -2.4116e+01-2.7507j, -1.0328e+00+0.7310j]],\n",
       "\n",
       "         [[-8.9577e-01+0.3567j, -2.0713e+01+1.7150j, -7.3396e-01-0.3228j],\n",
       "          [-6.0509e-01+0.2931j, -1.9207e+01+1.6515j, -1.0512e+00-0.3864j],\n",
       "          [-1.0332e+01+1.2113j, -4.6499e+01+2.5696j, -1.9913e+00+0.5318j]],\n",
       "\n",
       "         [[-5.8208e-01+0.0263j, -1.3460e+01+0.1265j, -4.7693e-01-0.0238j],\n",
       "          [-3.9319e-01+0.0216j, -1.2481e+01+0.1218j, -6.8309e-01-0.0285j],\n",
       "          [        nan+nanj, -3.0215e+01+0.1895j, -1.2940e+00+0.0392j]],\n",
       "\n",
       "         [[-4.7678e-01+0.6970j, -1.1025e+01-2.9314j, -3.9065e-01-0.6309j],\n",
       "          [-3.2206e-01+0.5729j, -1.0223e+01-3.0556j, -5.5952e-01-0.7551j],\n",
       "          [-5.4991e+00+2.3672j, -2.4749e+01-1.2612j, -1.0599e+00+1.0393j]]],\n",
       "\n",
       "\n",
       "        [[[-1.0195e+01-1.6488j, -1.6069e-01+0.2070j, -6.8007e+00+1.3466j],\n",
       "          [-1.3643e+01-1.9073j, -9.9563e-03-0.0515j, -4.4402e+00+1.0881j],\n",
       "          [-5.7847e+00-1.2420j, -1.4131e+00+0.6138j, -1.1531e+01+1.7535j]],\n",
       "\n",
       "         [[-1.5126e+01-0.6515j, -2.3839e-01+0.0818j, -1.0089e+01+0.5321j],\n",
       "          [-2.0241e+01-0.7537j, -1.4771e-02-0.0204j, -6.5872e+00+0.4300j],\n",
       "          [-8.5820e+00-0.4908j, -2.0965e+00+0.2426j, -1.7107e+01+0.6929j]],\n",
       "\n",
       "         [[-3.0535e+00-0.1947j, -4.8126e-02+0.0244j, -2.0368e+00+0.1590j],\n",
       "          [-4.0861e+00-0.2252j, -2.9819e-03-0.0061j, -1.3298e+00+0.1285j],\n",
       "          [        nan+nanj, -4.2323e-01+0.0725j, -3.4535e+00+0.2071j]],\n",
       "\n",
       "         [[-1.1306e+01-0.4748j, -1.7819e-01+0.0596j, -7.5412e+00+0.3877j],\n",
       "          [-1.5129e+01-0.5492j, -1.1041e-02-0.0148j, -4.9237e+00+0.3133j],\n",
       "          [-6.4146e+00-0.3576j, -1.5670e+00+0.1768j, -1.2786e+01+0.5049j]]],\n",
       "\n",
       "\n",
       "        [[[-2.2601e-01+0.3530j, -4.5963e+00+1.5919j, -8.9246e-01+0.7015j],\n",
       "          [-2.9929e+00-1.2846j, -3.7845e-03-0.0457j, -1.5894e+00-0.9361j],\n",
       "          [-2.5165e+00-1.1779j, -6.7472e-03+0.0610j, -1.2478e+00-0.8295j]],\n",
       "\n",
       "         [[-4.8562e-01+0.3924j, -9.8761e+00+1.7698j, -1.9176e+00+0.7798j],\n",
       "          [-6.4310e+00-1.4281j, -8.1319e-03-0.0508j, -3.4152e+00-1.0407j],\n",
       "          [-5.4073e+00-1.3095j, -1.4498e-02+0.0678j, -2.6812e+00-0.9221j]],\n",
       "\n",
       "         [[-5.3465e-01+0.1728j, -1.0873e+01+0.7793j, -2.1112e+00+0.3434j],\n",
       "          [-7.0802e+00-0.6288j, -8.9529e-03-0.0224j, -3.7599e+00-0.4583j],\n",
       "          [        nan+nanj, -1.5962e-02+0.0299j, -2.9519e+00-0.4060j]],\n",
       "\n",
       "         [[-6.0345e-01+0.1491j, -1.2272e+01+0.6723j, -2.3829e+00+0.2962j],\n",
       "          [-7.9913e+00-0.5425j, -1.0105e-02-0.0193j, -4.2438e+00-0.3953j],\n",
       "          [-6.7192e+00-0.4974j, -1.8015e-02+0.0258j, -3.3317e+00-0.3503j]]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"...dkp,dpf->fk...\", pos_output, scope_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e57dea52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-5.3094e-01-0.4083j],\n",
       "           [-2.4464e+00-0.7322j],\n",
       "           [-1.5411e+00-0.0452j],\n",
       "           [-1.6925e+00-0.4124j]],\n",
       "\n",
       "          [[-4.3661e-01-0.3991j],\n",
       "           [-1.2490e+00-0.4441j],\n",
       "           [-1.5873e+00-0.4144j],\n",
       "           [-4.4345e-01-0.2912j]],\n",
       "\n",
       "          [[-2.9707e+00+0.3724j],\n",
       "           [-2.0726e+00+0.1821j],\n",
       "           [-1.2360e+01+1.8397j],\n",
       "           [-2.7982e+00+0.7557j]],\n",
       "\n",
       "          [[-3.8262e+00+0.8995j],\n",
       "           [-8.3641e+00+1.6969j],\n",
       "           [-4.3808e+00+1.8448j],\n",
       "           [-9.2761e+00+2.1337j]],\n",
       "\n",
       "          [[-4.6458e-01+0.4903j],\n",
       "           [-8.9577e-01+0.3567j],\n",
       "           [-5.8208e-01+0.0263j],\n",
       "           [-4.7678e-01+0.6970j]],\n",
       "\n",
       "          [[-1.0195e+01-1.6488j],\n",
       "           [-1.5126e+01-0.6515j],\n",
       "           [-3.0535e+00-0.1947j],\n",
       "           [-1.1306e+01-0.4748j]],\n",
       "\n",
       "          [[-2.2601e-01+0.3530j],\n",
       "           [-4.8562e-01+0.3924j],\n",
       "           [-5.3465e-01+0.1728j],\n",
       "           [-6.0345e-01+0.1491j]]],\n",
       "\n",
       "\n",
       "         [[[-2.2431e-01-0.2654j],\n",
       "           [-1.0335e+00-0.4759j],\n",
       "           [-6.5107e-01-0.0294j],\n",
       "           [-7.1505e-01-0.2681j]],\n",
       "\n",
       "          [[-1.5363e+01-2.3676j],\n",
       "           [-4.3947e+01-2.6342j],\n",
       "           [-5.5850e+01-2.4582j],\n",
       "           [-1.5603e+01-1.7273j]],\n",
       "\n",
       "          [[-3.8285e+00-0.4227j],\n",
       "           [-2.6710e+00-0.2067j],\n",
       "           [-1.5929e+01-2.0885j],\n",
       "           [-3.6062e+00-0.8579j]],\n",
       "\n",
       "          [[-1.7693e+01+1.9342j],\n",
       "           [-3.8677e+01-2.6343j],\n",
       "           [-2.0257e+01-2.3161j],\n",
       "           [-4.2894e+01-1.6950j]],\n",
       "\n",
       "          [[-1.0743e+01+2.3576j],\n",
       "           [-2.0713e+01+1.7150j],\n",
       "           [-1.3460e+01+0.1265j],\n",
       "           [-1.1025e+01-2.9314j]],\n",
       "\n",
       "          [[-1.6069e-01+0.2070j],\n",
       "           [-2.3839e-01+0.0818j],\n",
       "           [-4.8126e-02+0.0244j],\n",
       "           [-1.7819e-01+0.0596j]],\n",
       "\n",
       "          [[-4.5963e+00+1.5919j],\n",
       "           [-9.8761e+00+1.7698j],\n",
       "           [-1.0873e+01+0.7793j],\n",
       "           [-1.2272e+01+0.6723j]]],\n",
       "\n",
       "\n",
       "         [[[-2.3957e+00-0.8674j],\n",
       "           [-1.1039e+01-1.5553j],\n",
       "           [-6.9536e+00-0.0961j],\n",
       "           [-7.6369e+00-0.8761j]],\n",
       "\n",
       "          [[-1.9595e+01-2.6739j],\n",
       "           [-5.6053e+01-2.9750j],\n",
       "           [-7.1236e+01-2.7762j],\n",
       "           [-1.9901e+01-1.9507j]],\n",
       "\n",
       "          [[-7.2906e-01+0.1845j],\n",
       "           [-5.0864e-01+0.0902j],\n",
       "           [-3.0334e+00+0.9114j],\n",
       "           [-6.8672e-01+0.3744j]],\n",
       "\n",
       "          [[-4.7185e+00+0.9989j],\n",
       "           [-1.0315e+01+1.8844j],\n",
       "           [-5.4024e+00+2.0487j],\n",
       "           [-1.1439e+01+2.3694j]],\n",
       "\n",
       "          [[-3.8066e-01-0.4438j],\n",
       "           [-7.3396e-01-0.3228j],\n",
       "           [-4.7693e-01-0.0238j],\n",
       "           [-3.9065e-01-0.6309j]],\n",
       "\n",
       "          [[-6.8007e+00+1.3466j],\n",
       "           [-1.0089e+01+0.5321j],\n",
       "           [-2.0368e+00+0.1590j],\n",
       "           [-7.5412e+00+0.3877j]],\n",
       "\n",
       "          [[-8.9246e-01+0.7015j],\n",
       "           [-1.9176e+00+0.7798j],\n",
       "           [-2.1112e+00+0.3434j],\n",
       "           [-2.3829e+00+0.2962j]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[-2.6958e+00-0.9201j],\n",
       "           [-1.2422e+01-1.6499j],\n",
       "           [-7.8248e+00-0.1019j],\n",
       "           [-8.5938e+00-0.9294j]],\n",
       "\n",
       "          [[-7.2240e+00+1.6235j],\n",
       "           [-2.0665e+01+1.8064j],\n",
       "           [-2.6263e+01+1.6857j],\n",
       "           [-7.3371e+00+1.1844j]],\n",
       "\n",
       "          [[-2.9001e+00+0.3679j],\n",
       "           [-2.0233e+00+0.1799j],\n",
       "           [-1.2066e+01+1.8177j],\n",
       "           [-2.7316e+00+0.7467j]],\n",
       "\n",
       "          [[-2.5474e+00-0.7339j],\n",
       "           [-5.5686e+00-1.3846j],\n",
       "           [-2.9166e+00-1.5053j],\n",
       "           [-6.1758e+00-1.7410j]],\n",
       "\n",
       "          [[-3.1383e-01+0.4030j],\n",
       "           [-6.0509e-01+0.2931j],\n",
       "           [-3.9319e-01+0.0216j],\n",
       "           [-3.2206e-01+0.5729j]],\n",
       "\n",
       "          [[-1.3643e+01-1.9073j],\n",
       "           [-2.0241e+01-0.7537j],\n",
       "           [-4.0861e+00-0.2252j],\n",
       "           [-1.5129e+01-0.5492j]],\n",
       "\n",
       "          [[-2.9929e+00-1.2846j],\n",
       "           [-6.4310e+00-1.4281j],\n",
       "           [-7.0802e+00-0.6288j],\n",
       "           [-7.9913e+00-0.5425j]]],\n",
       "\n",
       "\n",
       "         [[[-1.9234e+00-0.7772j],\n",
       "           [-8.8623e+00-1.3936j],\n",
       "           [-5.5827e+00-0.0861j],\n",
       "           [-6.1313e+00-0.7850j]],\n",
       "\n",
       "          [[-3.2603e-01-0.3449j],\n",
       "           [-9.3265e-01-0.3837j],\n",
       "           [-1.1853e+00-0.3581j],\n",
       "           [-3.3114e-01-0.2516j]],\n",
       "\n",
       "          [[-3.9096e+00-0.4272j],\n",
       "           [-2.7276e+00-0.2089j],\n",
       "           [-1.6267e+01-2.1105j],\n",
       "           [-3.6826e+00-0.8670j]],\n",
       "\n",
       "          [[-4.2794e-01+0.3008j],\n",
       "           [-9.3548e-01+0.5675j],\n",
       "           [-4.8997e-01+0.6170j],\n",
       "           [-1.0375e+00+0.7136j]],\n",
       "\n",
       "          [[-9.9616e+00+2.2703j],\n",
       "           [-1.9207e+01+1.6515j],\n",
       "           [-1.2481e+01+0.1218j],\n",
       "           [-1.0223e+01-3.0556j]],\n",
       "\n",
       "          [[-9.9563e-03-0.0515j],\n",
       "           [-1.4771e-02-0.0204j],\n",
       "           [-2.9819e-03-0.0061j],\n",
       "           [-1.1041e-02-0.0148j]],\n",
       "\n",
       "          [[-3.7845e-03-0.0457j],\n",
       "           [-8.1319e-03-0.0508j],\n",
       "           [-8.9529e-03-0.0224j],\n",
       "           [-1.0105e-02-0.0193j]]],\n",
       "\n",
       "\n",
       "         [[[-6.0567e+00-1.3792j],\n",
       "           [-2.7907e+01-2.4730j],\n",
       "           [-1.7580e+01-0.1528j],\n",
       "           [-1.9308e+01-1.3930j]],\n",
       "\n",
       "          [[-1.1622e+00-0.6512j],\n",
       "           [-3.3247e+00-0.7245j],\n",
       "           [-4.2252e+00-0.6761j],\n",
       "           [-1.1804e+00-0.4751j]],\n",
       "\n",
       "          [[-6.9427e-01+0.1800j],\n",
       "           [-4.8437e-01+0.0880j],\n",
       "           [-2.8886e+00+0.8894j],\n",
       "           [-6.5395e-01+0.3653j]],\n",
       "\n",
       "          [[-1.9042e+00-0.6345j],\n",
       "           [-4.1625e+00-1.1971j],\n",
       "           [-2.1802e+00-1.3015j],\n",
       "           [-4.6164e+00-1.5052j]],\n",
       "\n",
       "          [[-5.4521e-01-0.5311j],\n",
       "           [-1.0512e+00-0.3864j],\n",
       "           [-6.8309e-01-0.0285j],\n",
       "           [-5.5952e-01-0.7551j]],\n",
       "\n",
       "          [[-4.4402e+00+1.0881j],\n",
       "           [-6.5872e+00+0.4300j],\n",
       "           [-1.3298e+00+0.1285j],\n",
       "           [-4.9237e+00+0.3133j]],\n",
       "\n",
       "          [[-1.5894e+00-0.9361j],\n",
       "           [-3.4152e+00-1.0407j],\n",
       "           [-3.7599e+00-0.4583j],\n",
       "           [-4.2438e+00-0.3953j]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[-1.0286e+01+1.7973j],\n",
       "           [-4.7395e+01-3.0605j],\n",
       "           [-2.9856e+01+0.1991j],\n",
       "           [-3.2790e+01+1.8154j]],\n",
       "\n",
       "          [[-7.6894e-01-0.5297j],\n",
       "           [-2.1997e+00-0.5893j],\n",
       "           [-2.7955e+00-0.5500j],\n",
       "           [-7.8098e-01-0.3864j]],\n",
       "\n",
       "          [[-2.6452e+01+1.1112j],\n",
       "           [-1.8455e+01+0.5433j],\n",
       "           [       -inf-0.0000j],\n",
       "           [-2.4916e+01+2.2551j]],\n",
       "\n",
       "          [[-8.1728e-01+0.4157j],\n",
       "           [-1.7866e+00+0.7842j],\n",
       "           [-9.3574e-01+0.8526j],\n",
       "           [-1.9814e+00+0.9861j]],\n",
       "\n",
       "          [[-5.3585e+00+1.6651j],\n",
       "           [-1.0332e+01+1.2113j],\n",
       "           [-6.7137e+00+0.0893j],\n",
       "           [-5.4991e+00+2.3672j]],\n",
       "\n",
       "          [[-5.7847e+00-1.2420j],\n",
       "           [-8.5820e+00-0.4908j],\n",
       "           [-1.7325e+00-0.1467j],\n",
       "           [-6.4146e+00-0.3576j]],\n",
       "\n",
       "          [[-2.5165e+00-1.1779j],\n",
       "           [-5.4073e+00-1.3095j],\n",
       "           [-5.9532e+00-0.5766j],\n",
       "           [-6.7192e+00-0.4974j]]],\n",
       "\n",
       "\n",
       "         [[[-1.1987e+01+1.9403j],\n",
       "           [-5.5232e+01-2.8042j],\n",
       "           [-3.4793e+01+0.2149j],\n",
       "           [-3.8212e+01+1.9597j]],\n",
       "\n",
       "          [[-1.7103e+01-2.4981j],\n",
       "           [-4.8927e+01-2.7794j],\n",
       "           [-6.2179e+01-2.5937j],\n",
       "           [-1.7371e+01-1.8225j]],\n",
       "\n",
       "          [[-2.1401e+00+0.3161j],\n",
       "           [-1.4931e+00+0.1545j],\n",
       "           [-8.9043e+00+1.5615j],\n",
       "           [-2.0158e+00+0.6414j]],\n",
       "\n",
       "          [[-9.9493e+00+1.4505j],\n",
       "           [-2.1749e+01+2.7363j],\n",
       "           [-1.1392e+01+2.9749j],\n",
       "           [-2.4121e+01-2.8425j]],\n",
       "\n",
       "          [[-2.4116e+01-2.7507j],\n",
       "           [-4.6499e+01+2.5696j],\n",
       "           [-3.0215e+01+0.1895j],\n",
       "           [-2.4749e+01-1.2612j]],\n",
       "\n",
       "          [[-1.4131e+00+0.6138j],\n",
       "           [-2.0965e+00+0.2426j],\n",
       "           [-4.2323e-01+0.0725j],\n",
       "           [-1.5670e+00+0.1768j]],\n",
       "\n",
       "          [[-6.7472e-03+0.0610j],\n",
       "           [-1.4498e-02+0.0678j],\n",
       "           [-1.5962e-02+0.0299j],\n",
       "           [-1.8015e-02+0.0258j]]],\n",
       "\n",
       "\n",
       "         [[[-5.7027e+00+1.3383j],\n",
       "           [-2.6277e+01+2.3996j],\n",
       "           [-1.6553e+01+0.1483j],\n",
       "           [-1.8179e+01+1.3517j]],\n",
       "\n",
       "          [[-2.1555e+01-2.8044j],\n",
       "           [-6.1660e+01-3.1202j],\n",
       "           [-7.8361e+01-2.9117j],\n",
       "           [-2.1892e+01-2.0460j]],\n",
       "\n",
       "          [[-1.8262e+01+0.9233j],\n",
       "           [-1.2741e+01+0.4514j],\n",
       "           [-7.5983e+01-1.7218j],\n",
       "           [-1.7202e+01+1.8738j]],\n",
       "\n",
       "          [[-1.2548e+00+0.5151j],\n",
       "           [-2.7430e+00+0.9717j],\n",
       "           [-1.4367e+00+1.0565j],\n",
       "           [-3.0421e+00+1.2219j]],\n",
       "\n",
       "          [[-1.0328e+00+0.7310j],\n",
       "           [-1.9913e+00+0.5318j],\n",
       "           [-1.2940e+00+0.0392j],\n",
       "           [-1.0599e+00+1.0393j]],\n",
       "\n",
       "          [[-1.1531e+01+1.7535j],\n",
       "           [-1.7107e+01+0.6929j],\n",
       "           [-3.4535e+00+0.2071j],\n",
       "           [-1.2786e+01+0.5049j]],\n",
       "\n",
       "          [[-1.2478e+00-0.8295j],\n",
       "           [-2.6812e+00-0.9221j],\n",
       "           [-2.9519e+00-0.4060j],\n",
       "           [-3.3317e+00-0.3503j]]]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_layer(x_1, x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "14541a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-10.2860+1.7973j],\n",
       "         [-47.3948-3.0605j],\n",
       "         [     nan+nanj],\n",
       "         [-32.7898+1.8154j]],\n",
       "\n",
       "        [[ -0.7689-0.5297j],\n",
       "         [ -2.1997-0.5893j],\n",
       "         [     nan+nanj],\n",
       "         [ -0.7810-0.3864j]],\n",
       "\n",
       "        [[-26.4520+1.1112j],\n",
       "         [-18.4546+0.5433j],\n",
       "         [    -inf+nanj],\n",
       "         [-24.9157+2.2551j]],\n",
       "\n",
       "        [[ -0.8173+0.4157j],\n",
       "         [ -1.7866+0.7842j],\n",
       "         [     nan+nanj],\n",
       "         [ -1.9814+0.9861j]],\n",
       "\n",
       "        [[ -5.3585+1.6651j],\n",
       "         [-10.3318+1.2113j],\n",
       "         [     nan+nanj],\n",
       "         [ -5.4991+2.3672j]],\n",
       "\n",
       "        [[ -5.7847-1.2420j],\n",
       "         [ -8.5820-0.4908j],\n",
       "         [     nan+nanj],\n",
       "         [ -6.4146-0.3576j]],\n",
       "\n",
       "        [[ -2.5165-1.1779j],\n",
       "         [ -5.4073-1.3095j],\n",
       "         [     nan+nanj],\n",
       "         [ -6.7192-0.4974j]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope_tensor_s = scope_tensor.squeeze()\n",
    "pos_output_s = pos_output.squeeze()[0][0]\n",
    "\n",
    "pos_output_1 = pos_output.squeeze()[2][0].unsqueeze(0)\n",
    "\n",
    "torch.einsum(\"...dk,df->fk...\", pos_output_1, scope_tensor_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "23f6b9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-10.2860+1.7973j, -47.3948-3.0605j, -29.8559+0.1991j,\n",
       "          -32.7898+1.8154j],\n",
       "         [ -0.7689-0.5297j,  -2.1997-0.5893j,  -2.7955-0.5500j,\n",
       "           -0.7810-0.3864j],\n",
       "         [-26.4520+1.1112j, -18.4546+0.5433j,     -inf-0.0000j,\n",
       "          -24.9157+2.2551j],\n",
       "         [ -0.8173+0.4157j,  -1.7866+0.7842j,  -0.9357+0.8526j,\n",
       "           -1.9814+0.9861j],\n",
       "         [ -5.3585+1.6651j, -10.3318+1.2113j,  -6.7137+0.0893j,\n",
       "           -5.4991+2.3672j],\n",
       "         [ -5.7847-1.2420j,  -8.5820-0.4908j,  -1.7325-0.1467j,\n",
       "           -6.4146-0.3576j],\n",
       "         [ -2.5165-1.1779j,  -5.4073-1.3095j,  -5.9532-0.5766j,\n",
       "           -6.7192-0.4974j]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d635cdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope_tensor_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4666592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "pc.input_layer.params.param = torch.nn.Parameter(torch.log(torch.ones(tuple(pc.input_layer.params.shape))*3.3))\n",
    "# pc.inner_layers[0].params_in.param = torch.nn.Parameter(torch.log(0.25*torch.ones(tuple(pc.inner_layers[0].params_in.shape))))\n",
    "# pc.inner_layers[0].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[0].params_in.shape))*3.3)\n",
    "# pc.inner_layers[1].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[1].params_in.shape))*3.3)\n",
    "# pc.inner_layers[2].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[2].params_in.shape))*3.3)\n",
    "# pc.inner_layers[3].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[3].params_in.shape))*3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a99ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.inner_layers[0].params_in() #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(3, 8, 1)\n",
    "x2 = torch.randn(3, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc(x1, x2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pc(x1, x2): \n",
    "    return pc(x1.unsqueeze(-1), x2.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "eval_pc(x1.squeeze(), x2.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel\n",
    "\n",
    "# x = torch.randn(3, 5)\n",
    "covar_module = RBFKernel()\n",
    "covar_module.lengthscale = torch.tensor(3.3)\n",
    "covar_module(x1.squeeze(), x2.squeeze()).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c4d3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel\n",
    "x = torch.randn(3, 2)\n",
    "RBFKernel().lengthscale = torch.tensor(3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RBF input output = RBF kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel, SpectralMixtureKernel\n",
    "\n",
    "x = torch.randn(3, 5)\n",
    "covar_module = SpectralMixtureKernel(num_mixtures=2, ard_num_dims=5)\n",
    "covar_module.mixture_scales = torch.tensor(3.3).expand(1, 2, 1, 5)\n",
    "covar_module.mixture_means = torch.tensor(2.2).expand(1, 2, 1, 5)\n",
    "covar_module.mixture_weights = torch.tensor([0.5]).expand(1, 2, 1, 5)\n",
    "covar_module(x).evaluate()\n",
    "# covar_module.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.sm_kernel import SMKernelLayer\n",
    "input_la = SMKernelLayer(num_vars=5, num_output_units=1)\n",
    "\n",
    "input_la.params = torch.nn.Parameter(torch.ones((5,1))*3.3)\n",
    "\n",
    "# input_la(x1, x2).squeeze().shape\n",
    "\n",
    "# input_la(x.unsqueeze(-1), x.unsqueeze(-1)).shape\n",
    "\n",
    "torch.prod(torch.exp(input_la(x.unsqueeze(-1), x.unsqueeze(-1)).squeeze()), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f025e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_la = RBFKernelLayer(num_vars=20, num_output_units=1)\n",
    "\n",
    "input_la.params = torch.nn.Parameter(torch.ones((20,1))*3.3)\n",
    "\n",
    "# input_la(x1, x2).squeeze().shape\n",
    "torch.prod(input_la(x1, x1).squeeze(), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facf1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel\n",
    "\n",
    "x = torch.randn(3, 5)\n",
    "covar_module = RBFKernel()\n",
    "covar_module.lengthscale = torch.tensor(3.3)\n",
    "covar_module(x).evaluate()\n",
    "# covar_module.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0dc104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.rbf_kernel import RBFKernelLayer\n",
    "input_la = RBFKernelLayer(num_vars=5, num_output_units=1)\n",
    "\n",
    "input_la.params.param = torch.nn.Parameter(torch.log(torch.ones(tuple(input_la.params.shape))*3.3))\n",
    "# pc.input_layer.params.param = torch.nn.Parameter(torch.log(torch.ones(tuple(pc.input_layer.params.shape))*3.3))\n",
    "\n",
    "# input_la(x1, x2).squeeze().shape\n",
    "\n",
    "# input_la(x.unsqueeze(-1), x.unsqueeze(-1)).shape\n",
    "\n",
    "torch.prod(torch.exp(input_la(x.unsqueeze(-1), x.unsqueeze(-1)).squeeze()), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd562b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd606c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(0, 1, 3)\n",
    "torch.sin(train_x * (2 * math.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a2c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "# train_x = torch.linspace(0, 1, 3)\n",
    "# train_y = torch.sin(train_x * (2 * math.pi))\n",
    "train_x = torch.rand((3, 5))\n",
    "train_y = torch.rand((3))\n",
    "\n",
    "covar_module = SpectralMixtureKernel(num_mixtures=4, ard_num_dims=5)\n",
    "covar_module.initialize_from_data(train_x, train_y)\n",
    "covar_module(train_x).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f94551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.sm_kernel import SMKernelLayer\n",
    "input_la = SMKernelLayer(num_vars=1, num_output_units=4)\n",
    "\n",
    "input_la.params_mu.param = torch.nn.Parameter(covar_module.mixture_means)\n",
    "input_la.params_sigma.param = torch.nn.Parameter(torch.log(covar_module.mixture_scales))\n",
    "\n",
    "\n",
    "to_be_weighted = input_la(train_x.unsqueeze(-1), train_x.unsqueeze(-1))\n",
    "\n",
    "to_be_weighted = torch.prod(to_be_weighted, dim=2, keepdim=True) / 5\n",
    "\n",
    "tensor1_expanded = covar_module.mixture_weights.expand_as(to_be_weighted.squeeze(-1))\n",
    "\n",
    "# Element-wise multiplication and then sum over the inner product dimension (dimension 3 after squeeze)\n",
    "(tensor1_expanded * to_be_weighted.squeeze(-1)).sum(dim=3).squeeze()\n",
    "\n",
    "# torch.prod(finalfinal, dim=-1, keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_module.mixture_scales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b267ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_module(x1).evaluate().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d377b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.unsqueeze(-1).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = torch.tensor([[-0.6281], [ 0.1011], [ 0.0664]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.rbf_kernel import RBFKernelLayer\n",
    "input_la = RBFKernelLayer(num_vars=2, num_output_units=1)\n",
    "\n",
    "input_la.params = torch.nn.Parameter(torch.ones((1,1))*3.3)\n",
    "\n",
    "input_la(x_2.unsqueeze(-1), x_2.unsqueeze(-1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45183425",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_la.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a28677",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones((2,1))*3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.unsqueeze(-1).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed03208",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_la(x.unsqueeze(-1), x.unsqueeze(-1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756535e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cdist(x1, x2, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(data_train, shuffle=True, batch_size=256)\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=256)\n",
    "optimizer = optim.SGD(pc.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the constructed PC is not necessarily normalized, we construct the integral circuit that will compute the partition function. Note that parameters are shared and therefore there is no additional memory required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.models.functional import integrate\n",
    "pc_pf = integrate(pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we optimize the parameters for 5 epochs by minimizing the negative log-likelohood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch_idx in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch, _ in train_dataloader:\n",
    "        batch = batch.to(device).unsqueeze(dim=-1)  # Add a channel dimension\n",
    "        log_score = pc(batch)\n",
    "        log_pf = pc_pf(batch)     # Compute the partition function\n",
    "        lls = log_score - log_pf  # Compute the log-likelihood\n",
    "        loss = -torch.mean(lls)   # The loss is the negative average log-likelihood\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss * len(batch)\n",
    "        # Clamp the parameters to ensure they are in the intended domain\n",
    "        # This is needed if we do not use any reparametrization to ensure parameters non-negativity\n",
    "        # In our case, clamping is disable becuase we reparameterize via exponentiation (see above)\n",
    "        #for layer in model.inner_layers:\n",
    "        #    layer.clamp_params()\n",
    "    print(f\"Epoch {epoch_idx}: Average NLL: {running_loss / len(data_train):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then evaluate our model on test data by computing the average log-likelihood and bits per dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pc.eval()\n",
    "    log_pf = pc_pf(torch.empty((), device=device))  # Compute the partition function once for testing\n",
    "    test_lls = 0.0\n",
    "    for batch, _ in test_dataloader:\n",
    "        log_score = pc(batch.to(device).unsqueeze(dim=-1))\n",
    "        lls = log_score - log_pf\n",
    "        test_lls += lls.sum().item()\n",
    "    average_ll = test_lls / len(data_test)\n",
    "    bpd = -average_ll / (num_variables * np.log(2.0))\n",
    "    print(f\"Average test LL: {average_ll:.3f}\")\n",
    "    print(f\"Bits per dimension: {bpd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4acbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a9727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import gpytorch\n",
    "\n",
    "# from ..functions import RBFCovariance\n",
    "# from ..settings import trace_mode\n",
    "from gpytorch.kernels import Kernel\n",
    "\n",
    "\n",
    "def postprocess_rbf(dist_mat):\n",
    "    return dist_mat.div_(-2).exp_()\n",
    "\n",
    "\n",
    "class TestRBFKernel(Kernel):\n",
    "    r\"\"\"\n",
    "    Computes a covariance matrix based on the RBF (squared exponential) kernel\n",
    "    between inputs :math:`\\mathbf{x_1}` and :math:`\\mathbf{x_2}`:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "       \\begin{equation*}\n",
    "          k_{\\text{RBF}}(\\mathbf{x_1}, \\mathbf{x_2}) = \\exp \\left( -\\frac{1}{2}\n",
    "          (\\mathbf{x_1} - \\mathbf{x_2})^\\top \\Theta^{-2} (\\mathbf{x_1} - \\mathbf{x_2}) \\right)\n",
    "       \\end{equation*}\n",
    "\n",
    "    where :math:`\\Theta` is a :attr:`lengthscale` parameter.\n",
    "    See :class:`gpytorch.kernels.Kernel` for descriptions of the lengthscale options.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        This kernel does not have an `outputscale` parameter. To add a scaling parameter,\n",
    "        decorate this kernel with a :class:`gpytorch.kernels.ScaleKernel`.\n",
    "\n",
    "    Args:\n",
    "        :attr:`ard_num_dims` (int, optional):\n",
    "            Set this if you want a separate lengthscale for each\n",
    "            input dimension. It should be `d` if :attr:`x1` is a `n x d` matrix. Default: `None`\n",
    "        :attr:`batch_shape` (torch.Size, optional):\n",
    "            Set this if you want a separate lengthscale for each\n",
    "            batch of input data. It should be `b` if :attr:`x1` is a `b x n x d` tensor. Default: `torch.Size([])`.\n",
    "        :attr:`active_dims` (tuple of ints, optional):\n",
    "            Set this if you want to compute the covariance of only a few input dimensions. The ints\n",
    "            corresponds to the indices of the dimensions. Default: `None`.\n",
    "        :attr:`lengthscale_prior` (Prior, optional):\n",
    "            Set this if you want to apply a prior to the lengthscale parameter.  Default: `None`.\n",
    "        :attr:`lengthscale_constraint` (Constraint, optional):\n",
    "            Set this if you want to apply a constraint to the lengthscale parameter. Default: `Positive`.\n",
    "        :attr:`eps` (float):\n",
    "            The minimum value that the lengthscale can take (prevents divide by zero errors). Default: `1e-6`.\n",
    "\n",
    "    Attributes:\n",
    "        :attr:`lengthscale` (Tensor):\n",
    "            The lengthscale parameter. Size/shape of parameter depends on the\n",
    "            :attr:`ard_num_dims` and :attr:`batch_shape` arguments.\n",
    "\n",
    "    Example:\n",
    "        >>> x = torch.randn(10, 5)\n",
    "        >>> # Non-batch: Simple option\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        >>> # Non-batch: ARD (different lengthscale for each input dimension)\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=5))\n",
    "        >>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n",
    "        >>>\n",
    "        >>> batch_x = torch.randn(2, 10, 5)\n",
    "        >>> # Batch: Simple option\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        >>> # Batch: different lengthscale for each batch\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(batch_shape=torch.Size([2])))\n",
    "        >>> covar = covar_module(x)  # Output: LazyTensor of size (2 x 10 x 10)\n",
    "    \"\"\"\n",
    "\n",
    "    has_lengthscale = True\n",
    "\n",
    "    def forward(self, x1, x2, diag=False, **params):\n",
    "\n",
    "        x1_ = x1.div(self.lengthscale)\n",
    "        x2_ = x2.div(self.lengthscale)\n",
    "        \n",
    "        # print (\"x1, x2\", x1_, x2_)\n",
    "        \n",
    "        return self.covar_dist(\n",
    "            x1_, x2_, square_dist=True, diag=diag, dist_postprocess_func=postprocess_rbf, postprocess=True, **params\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernel = TestRBFKernel()\n",
    "test_kernel.lengthscale = torch.tensor(3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0114f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernel.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4731298",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernel(x1.squeeze(),x2.squeeze()).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8887c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2c61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef03dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5028f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cirkit1",
   "language": "python",
   "name": "cirkit1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
