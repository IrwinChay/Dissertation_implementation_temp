{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate a PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:00.305482Z",
     "start_time": "2024-03-14T14:35:59.231534Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:01.996183Z",
     "start_time": "2024-03-14T14:36:01.950399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")  # The device to use, e.g., \"cpu\", \"cuda\", \"cuda:1\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:03.245505Z",
     "start_time": "2024-03-14T14:36:03.190582Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:05.899377Z",
     "start_time": "2024-03-14T14:36:05.858609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc8588db990>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(4)\n",
    "np.random.seed(4)\n",
    "torch.manual_seed(4)\n",
    "# if 'cuda' in device.type:\n",
    "#     torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and test splits of MNIST, and preprocess them by flattening the tensor images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:10.329915Z",
     "start_time": "2024-03-14T14:36:09.956962Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (255 * x.view(-1)).long())\n",
    "])\n",
    "data_train = datasets.MNIST('datasets', train=True, download=True, transform=transform)\n",
    "data_test = datasets.MNIST('datasets', train=False, download=True, transform=transform)\n",
    "num_variables = data_train[0][0].shape[0]\n",
    "height, width = 28, 28\n",
    "print(f\"Number of variables: {num_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T12:41:27.661486Z",
     "start_time": "2024-03-14T12:41:27.534444Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(data_train[0][0].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Class: {data_train[0][1]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3137ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37115b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from uci_datasets import Dataset\n",
    "\n",
    "from ignite.engine import Events, Engine\n",
    "from ignite.metrics import Average, Loss\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.mlls import VariationalELBO\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the region graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e4bf454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.region_graph.poon_domingos import PoonDomingos\n",
    "from cirkit.region_graph.random_binary_tree import RandomBinaryTree\n",
    "from cirkit.region_graph.fully_factorized import FullyFactorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1a2c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.models.gp import CircuitGP, initial_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a _Quad Graph_ region graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:19.883137Z",
     "start_time": "2024-03-14T14:36:19.844640Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Others available region graphs are _Poon Domingos_ and _QuadTree_, whose imports are showed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:18.569812Z",
     "start_time": "2024-03-14T14:36:18.526134Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to choose both the input and inner layers of our circuit. As input layer we select the _CategoricalLayer_ with 256 categories (the number of pixel values). For the inner layer instead, we choose the _uncollapsed CP_ layer with rank 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:22.044953Z",
     "start_time": "2024-03-14T14:36:21.997532Z"
    }
   },
   "outputs": [],
   "source": [
    "from cirkit.layers.input.exp_family import CategoricalLayer\n",
    "from cirkit.layers.sum_product import CPLayer\n",
    "from cirkit.layers.input.rbf_kernel import RBFKernelLayer\n",
    "\n",
    "efamily_cls = RBFKernelLayer\n",
    "efamily_kwargs = {}\n",
    "layer_cls = CPLayer\n",
    "layer_kwargs = {'rank': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the tensorized PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build our tensorized PC by specifying the region graph and layers we chose previously. In addition, we can scale the architecture by increasing the number of input and inner units. We can also have circuits with multiple output units by choosing _num_classes > 1_. However, in this notebook we only estimate the distribution of the images and marginalize out the class variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure weights are non-negative we reparametrize them via exponentiation. Several reparametrization functions are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f01d2ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.region_graph.quad_tree import QuadTree\n",
    "# region_graph = QuadTree(width, height, struct_decomp=False)\n",
    "region_graph = RandomBinaryTree(num_vars=8, depth=3, num_repetitions=6)\n",
    "# region_graph = FullyFactorized(num_vars=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:23.646351Z",
     "start_time": "2024-03-14T14:36:23.593945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorizedPC(\n",
      "  (input_layer): RBFKernelLayer(\n",
      "    (params): ReparamExp()\n",
      "  )\n",
      "  (scope_layer): ScopeLayer()\n",
      "  (inner_layers): ModuleList(\n",
      "    (0-2): 3 x CollapsedCPLayer(\n",
      "      (params_in): ReparamExp()\n",
      "    )\n",
      "    (3): SumLayer(\n",
      "      (params): ReparamExp()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from cirkit.reparams.leaf import ReparamExp, ReparamLogSoftmax, ReparamSoftmax\n",
    "from cirkit.models.tensorized_circuit import TensorizedPC\n",
    "pc = TensorizedPC.from_region_graph(\n",
    "    region_graph,\n",
    "    num_inner_units=1,\n",
    "    num_input_units=1,\n",
    "    efamily_cls=efamily_cls,\n",
    "    efamily_kwargs=efamily_kwargs,\n",
    "    layer_cls=layer_cls,\n",
    "    layer_kwargs=layer_kwargs,\n",
    "    num_classes=1,\n",
    "    reparam=ReparamExp # ReparamLogSoftmax # ReparamExp ReparamSoftmax\n",
    ")\n",
    "pc.to(device)\n",
    "print(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "be79dbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1])\n",
      "torch.Size([24, 2, 1, 1])\n",
      "torch.Size([12, 2, 1, 1])\n",
      "torch.Size([6, 2, 1, 1])\n",
      "torch.Size([1, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "for param in pc.parameters(): \n",
    "    print (param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4b879cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "baaefe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kin40k dataset, N=40000, d=8\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(\"kin40k\")\n",
    "x_train, y_train, x_test, y_test = data.get_split(split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8905bdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36000, 8), (4000, 8))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "42d1accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_real = x_train[:32000] #32000 # 2053   36584    36584     39063   13281    2672   # RE-RUN # 13279   # 1279   4701  824\n",
    "y_train_real = y_train[:32000]\n",
    "y_train_real = y_train_real.squeeze()\n",
    "x_val = x_train[32000:]\n",
    "y_val = y_train[32000:]\n",
    "y_val = y_val.squeeze()\n",
    "y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "84cc07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x_train_real.mean(axis=0)\n",
    "std = x_train_real.std(axis=0)\n",
    "\n",
    "x_train_real_normalized = (x_train_real - mean) / std\n",
    "x_val_normalized = (x_val - mean) / std\n",
    "x_test_normalized = (x_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "04a58de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class IdentityMapping(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdentityMapping, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74111ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6f58cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Define the linear layer with input dimension 8 and output dimension 256\n",
    "        self.linear = nn.Linear(in_features=8, out_features=128)\n",
    "        # Define the ReLU activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply linear layer and then ReLU activation to the input x\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7d527e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 32000 datapoints for 50 epochs\n",
      "f_X_samples torch.Size([32000, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irwinchay/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_lengthscale tensor(3.8958)\n",
      "All circuit parameters shape: \n",
      "torch.Size([8, 1])\n",
      "torch.Size([24, 2, 1, 1])\n",
      "torch.Size([12, 2, 1, 1])\n",
      "torch.Size([6, 2, 1, 1])\n",
      "torch.Size([1, 6, 1])\n",
      "initial_lengthscale torch.Size([])\n",
      "lengthscales shape torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(24)\n",
    "torch.manual_seed(24) ####################### CHANGE\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# X_train, y_train = make_data(n_samples)\n",
    "# X_test, y_test = X_train, y_train\n",
    "\n",
    "# x_train, y_train, x_test, y_test\n",
    "\n",
    "ds_train = torch.utils.data.TensorDataset(torch.from_numpy(x_train_real).float(), torch.from_numpy(y_train_real).float())\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, drop_last=True) # suffle \n",
    "\n",
    "ds_val = torch.utils.data.TensorDataset(torch.from_numpy(x_val).float(), torch.from_numpy(y_val).float())\n",
    "dl_val = torch.utils.data.DataLoader(ds_val, batch_size=512, shuffle=False)\n",
    "\n",
    "ds_test = torch.utils.data.TensorDataset(torch.from_numpy(x_test).float(), torch.from_numpy(y_test).float())\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=512, shuffle=False)\n",
    "\n",
    "# steps = 5e3\n",
    "epochs = 50\n",
    "print(f\"Training with {len(x_train_real)} datapoints for {epochs} epochs\")\n",
    "\n",
    "# Change this boolean to False for SNGP\n",
    "\n",
    "input_dim = 8 # input di  # 128\n",
    "\n",
    "num_outputs = 1 # regression with 1D output\n",
    "\n",
    "feature_extractor = IdentityMapping()\n",
    "\n",
    "n_inducing_points = 10\n",
    "kernel = \"HBF\" ################# change \n",
    "\n",
    "initial_inducing_points, initial_lengthscale = initial_values(\n",
    "        ds_train, feature_extractor, n_inducing_points\n",
    ")\n",
    "\n",
    "gp_model = CircuitGP(\n",
    "    num_outputs=num_outputs,\n",
    "    num_features=input_dim,          # CHANGE features / input_dim\n",
    "    initial_lengthscale=initial_lengthscale,\n",
    "    initial_inducing_points=initial_inducing_points,\n",
    "    circuit=pc\n",
    "    # kernel=kernel,\n",
    ")\n",
    "    \n",
    "likelihood = GaussianLikelihood()\n",
    "elbo_fn = VariationalELBO(likelihood, gp_model, num_data=len(ds_train))\n",
    "loss_fn = lambda x, y: -elbo_fn(x, y)\n",
    "    \n",
    "# learning rate   \n",
    "lr = 1e-5\n",
    "\n",
    "parameters = [\n",
    "    {\"params\": gp_model.parameters(), \"lr\": lr},\n",
    "]\n",
    "\n",
    "parameters.append({\"params\": likelihood.parameters(), \"lr\": lr})\n",
    "    \n",
    "    \n",
    "optimizer = torch.optim.Adam(parameters)\n",
    "pbar = ProgressBar()\n",
    "\n",
    "step_counter = 0\n",
    "\n",
    "def step(engine, batch):\n",
    "    \n",
    "    global step_counter\n",
    "    step_counter += 1\n",
    "    \n",
    "    gp_model.train()\n",
    "    likelihood.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x, y = batch\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    y_pred = gp_model(x) # get y\n",
    "    \n",
    "    \n",
    "    loss = loss_fn(y_pred, y) # loss\n",
    "    # print(\"loss\", loss)\n",
    "    \n",
    "    if torch.isnan(loss).any():\n",
    "        print(f\"Step {step_counter}: NaN detected in loss.\")\n",
    "        print(\"loss\", loss)\n",
    "        print(\"y_pred\", y_pred)\n",
    "    \n",
    "    if torch.isnan(loss).any():\n",
    "        print(\"NaN detected in loss, saving model and stopping.\")\n",
    "        # Save model weights before termination\n",
    "        torch.save(gp_model.state_dict(), 'model_weights_before_nan.pt')\n",
    "        engine.terminate()\n",
    "        return\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    gp_model.eval() # set to eval\n",
    "    likelihood.eval()\n",
    "    \n",
    "    x, y = batch\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    y_pred = gp_model(x)   \n",
    "    return y_pred, y\n",
    "\n",
    "    \n",
    "trainer = Engine(step)\n",
    "evaluator = Engine(eval_step)\n",
    "\n",
    "metric = Average()\n",
    "metric.attach(trainer, \"loss\")\n",
    "pbar.attach(trainer)\n",
    "\n",
    "metric = Loss(lambda y_pred, y: - likelihood.expected_log_prob(y, y_pred).mean())\n",
    "\n",
    "metric.attach(evaluator, \"loss\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=int(epochs/20) + 1))\n",
    "def log_results(trainer):\n",
    "    evaluator.run(dl_val) # val dataset\n",
    "    print(f\"Results - Epoch: {trainer.state.epoch} - \"\n",
    "          f\"Val Loss: {evaluator.state.metrics['loss']:.2f} - \"\n",
    "          f\"Train Loss: {trainer.state.metrics['loss']:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e7cab3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([24, 2, 1, 1])\n",
      "torch.Size([12, 2, 1, 1])\n",
      "torch.Size([6, 2, 1, 1])\n",
      "torch.Size([1, 6, 1])\n",
      "torch.Size([1])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for index, param in enumerate(gp_model.parameters()): \n",
    "    # if (index==2):\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "82340f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cadbed22bf43bbacdd12f665d4d20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a71206e77084c30bf9f0272e73988c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e8eabf972b46b096422b85afae7681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 3 - Val Loss: 2757209472424265383936.00 - Train Loss: 2757453145030128566272.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2343465a0c4c6f9c373f24eb0c492e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916c00ecae6a44fa8c131f7e0a2d1f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d36376d90994b0e99e9f730f0b40415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 6 - Val Loss: 2754459754635777802240.00 - Train Loss: 2754588730973706256384.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afb0b22a0614c6e9faa61115f94ebf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0795e1e4551744d5b553a1c7d6aa4479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e41a3cff68498aa3aedaffd45d4aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results - Epoch: 9 - Val Loss: 2751808899866310475776.00 - Train Loss: 2751924864741965561856.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a74dbfc650841ba8319aac891c68ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1000]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:898\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:941\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 941\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:999\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 999\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:965\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 965\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    967\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/ignite/engine/engine.py:1074\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "Cell \u001b[0;32mIn[96], line 100\u001b[0m, in \u001b[0;36mstep\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     97\u001b[0m     engine\u001b[38;5;241m.\u001b[39mterminate()\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cirkit1/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.run(dl_train, max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537363e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in likelihood.parameters(): \n",
    "    print (param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c666fe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.86\n"
     ]
    }
   ],
   "source": [
    "from ignite.metrics import RootMeanSquaredError\n",
    "import torch\n",
    "\n",
    "# Assuming you have a function to compute RMSE, or you're using Ignite's RMSE metric\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    gp_model.eval()  # Ensure model is in evaluation mode\n",
    "    likelihood.eval()\n",
    "    \n",
    "    x, y = batch\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    # Assuming your model outputs a distribution, e.g., MultivariateNormal\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        distribution = gp_model(x)\n",
    "        y_pred = distribution.mean  # Use the mean of the distribution as the prediction\n",
    "\n",
    "    return y_pred, y\n",
    "\n",
    "# Update the evaluator engine\n",
    "evaluator = Engine(eval_step)\n",
    "\n",
    "# Attach the RMSE metric to the evaluator\n",
    "rmse = RootMeanSquaredError()\n",
    "rmse.attach(evaluator, \"RMSE\")\n",
    "\n",
    "# After training, run the evaluator on the test dataset to compute the RMSE\n",
    "evaluator.run(dl_test)\n",
    "\n",
    "# Retrieve and display the RMSE\n",
    "test_rmse = evaluator.state.metrics['RMSE']\n",
    "print(f\"Test RMSE: {test_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b5f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37ce73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c2c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fb408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5011843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed631b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d906bdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13f66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1c1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8794c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed311e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0798ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:25.724719Z",
     "start_time": "2024-03-14T14:36:25.680948Z"
    }
   },
   "outputs": [],
   "source": [
    "pc.input_layer.params.param.shape\n",
    "# (self.num_vars, self.num_output_units, self.num_replicas, self.num_suff_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:35:35.437628Z",
     "start_time": "2024-03-14T14:35:35.393853Z"
    }
   },
   "outputs": [],
   "source": [
    "pc.scope_layer.scope.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:36:27.302533Z",
     "start_time": "2024-03-14T14:36:27.260539Z"
    }
   },
   "outputs": [],
   "source": [
    "pc.inner_layers[0].params_in() #.param #.shape #.param.shape\n",
    "# (F, H, I, O)\n",
    "# (fold count, arity, input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:11:52.080085Z",
     "start_time": "2024-03-14T13:11:52.073368Z"
    }
   },
   "outputs": [],
   "source": [
    "from cirkit.models.rbf_kernel import RBFCircuitKernel\n",
    "\n",
    "circuit_kernel = RBFCircuitKernel(pc, batch_shape=torch.Size([]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:06:06.337943Z",
     "start_time": "2024-03-14T13:06:06.330408Z"
    }
   },
   "outputs": [],
   "source": [
    "circuit_kernel(x1.squeeze(), x2.squeeze()).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:06:07.504758Z",
     "start_time": "2024-03-14T13:06:07.498492Z"
    }
   },
   "outputs": [],
   "source": [
    "x1.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T13:06:09.102855Z",
     "start_time": "2024-03-14T13:06:09.096848Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57dea52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4666592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "pc.input_layer.params.param = torch.nn.Parameter(torch.log(torch.ones(tuple(pc.input_layer.params.shape))*3.3))\n",
    "# pc.inner_layers[0].params_in.param = torch.nn.Parameter(torch.log(0.25*torch.ones(tuple(pc.inner_layers[0].params_in.shape))))\n",
    "# pc.inner_layers[0].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[0].params_in.shape))*3.3)\n",
    "# pc.inner_layers[1].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[1].params_in.shape))*3.3)\n",
    "# pc.inner_layers[2].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[2].params_in.shape))*3.3)\n",
    "# pc.inner_layers[3].params_in = torch.nn.Parameter(torch.ones(tuple(pc.inner_layers[3].params_in.shape))*3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a99ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.inner_layers[0].params_in() #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(3, 8, 1)\n",
    "x2 = torch.randn(3, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc(x1, x2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pc(x1, x2): \n",
    "    return pc(x1.unsqueeze(-1), x2.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "eval_pc(x1.squeeze(), x2.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel\n",
    "\n",
    "# x = torch.randn(3, 5)\n",
    "covar_module = RBFKernel()\n",
    "covar_module.lengthscale = torch.tensor(3.3)\n",
    "covar_module(x1.squeeze(), x2.squeeze()).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c4d3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel\n",
    "x = torch.randn(3, 2)\n",
    "RBFKernel().lengthscale = torch.tensor(3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RBF input output = RBF kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel, SpectralMixtureKernel\n",
    "\n",
    "x = torch.randn(3, 5)\n",
    "covar_module = SpectralMixtureKernel(num_mixtures=2, ard_num_dims=5)\n",
    "covar_module.mixture_scales = torch.tensor(3.3).expand(1, 2, 1, 5)\n",
    "covar_module.mixture_means = torch.tensor(2.2).expand(1, 2, 1, 5)\n",
    "covar_module.mixture_weights = torch.tensor([0.5]).expand(1, 2, 1, 5)\n",
    "covar_module(x).evaluate()\n",
    "# covar_module.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.sm_kernel import SMKernelLayer\n",
    "input_la = SMKernelLayer(num_vars=5, num_output_units=1)\n",
    "\n",
    "input_la.params = torch.nn.Parameter(torch.ones((5,1))*3.3)\n",
    "\n",
    "# input_la(x1, x2).squeeze().shape\n",
    "\n",
    "# input_la(x.unsqueeze(-1), x.unsqueeze(-1)).shape\n",
    "\n",
    "torch.prod(torch.exp(input_la(x.unsqueeze(-1), x.unsqueeze(-1)).squeeze()), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f025e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_la = RBFKernelLayer(num_vars=20, num_output_units=1)\n",
    "\n",
    "input_la.params = torch.nn.Parameter(torch.ones((20,1))*3.3)\n",
    "\n",
    "# input_la(x1, x2).squeeze().shape\n",
    "torch.prod(input_la(x1, x1).squeeze(), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facf1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel\n",
    "\n",
    "x = torch.randn(3, 5)\n",
    "covar_module = RBFKernel()\n",
    "covar_module.lengthscale = torch.tensor(3.3)\n",
    "covar_module(x).evaluate()\n",
    "# covar_module.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0dc104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.rbf_kernel import RBFKernelLayer\n",
    "input_la = RBFKernelLayer(num_vars=5, num_output_units=1)\n",
    "\n",
    "input_la.params.param = torch.nn.Parameter(torch.log(torch.ones(tuple(input_la.params.shape))*3.3))\n",
    "# pc.input_layer.params.param = torch.nn.Parameter(torch.log(torch.ones(tuple(pc.input_layer.params.shape))*3.3))\n",
    "\n",
    "# input_la(x1, x2).squeeze().shape\n",
    "\n",
    "# input_la(x.unsqueeze(-1), x.unsqueeze(-1)).shape\n",
    "\n",
    "torch.prod(torch.exp(input_la(x.unsqueeze(-1), x.unsqueeze(-1)).squeeze()), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd562b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd606c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(0, 1, 3)\n",
    "torch.sin(train_x * (2 * math.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a2c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "# train_x = torch.linspace(0, 1, 3)\n",
    "# train_y = torch.sin(train_x * (2 * math.pi))\n",
    "train_x = torch.rand((3, 5))\n",
    "train_y = torch.rand((3))\n",
    "\n",
    "covar_module = SpectralMixtureKernel(num_mixtures=4, ard_num_dims=5)\n",
    "covar_module.initialize_from_data(train_x, train_y)\n",
    "covar_module(train_x).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f94551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.sm_kernel import SMKernelLayer\n",
    "input_la = SMKernelLayer(num_vars=1, num_output_units=4)\n",
    "\n",
    "input_la.params_mu.param = torch.nn.Parameter(covar_module.mixture_means)\n",
    "input_la.params_sigma.param = torch.nn.Parameter(torch.log(covar_module.mixture_scales))\n",
    "\n",
    "\n",
    "to_be_weighted = input_la(train_x.unsqueeze(-1), train_x.unsqueeze(-1))\n",
    "\n",
    "to_be_weighted = torch.prod(to_be_weighted, dim=2, keepdim=True) / 5\n",
    "\n",
    "tensor1_expanded = covar_module.mixture_weights.expand_as(to_be_weighted.squeeze(-1))\n",
    "\n",
    "# Element-wise multiplication and then sum over the inner product dimension (dimension 3 after squeeze)\n",
    "(tensor1_expanded * to_be_weighted.squeeze(-1)).sum(dim=3).squeeze()\n",
    "\n",
    "# torch.prod(finalfinal, dim=-1, keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_module.mixture_scales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b267ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_module(x1).evaluate().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d377b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.unsqueeze(-1).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = torch.tensor([[-0.6281], [ 0.1011], [ 0.0664]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.layers.input.rbf_kernel import RBFKernelLayer\n",
    "input_la = RBFKernelLayer(num_vars=2, num_output_units=1)\n",
    "\n",
    "input_la.params = torch.nn.Parameter(torch.ones((1,1))*3.3)\n",
    "\n",
    "input_la(x_2.unsqueeze(-1), x_2.unsqueeze(-1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45183425",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_la.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a28677",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones((2,1))*3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.unsqueeze(-1).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed03208",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_la(x.unsqueeze(-1), x.unsqueeze(-1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756535e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cdist(x1, x2, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(data_train, shuffle=True, batch_size=256)\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=256)\n",
    "optimizer = optim.SGD(pc.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the constructed PC is not necessarily normalized, we construct the integral circuit that will compute the partition function. Note that parameters are shared and therefore there is no additional memory required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.models.functional import integrate\n",
    "pc_pf = integrate(pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we optimize the parameters for 5 epochs by minimizing the negative log-likelohood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch_idx in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch, _ in train_dataloader:\n",
    "        batch = batch.to(device).unsqueeze(dim=-1)  # Add a channel dimension\n",
    "        log_score = pc(batch)\n",
    "        log_pf = pc_pf(batch)     # Compute the partition function\n",
    "        lls = log_score - log_pf  # Compute the log-likelihood\n",
    "        loss = -torch.mean(lls)   # The loss is the negative average log-likelihood\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss * len(batch)\n",
    "        # Clamp the parameters to ensure they are in the intended domain\n",
    "        # This is needed if we do not use any reparametrization to ensure parameters non-negativity\n",
    "        # In our case, clamping is disable becuase we reparameterize via exponentiation (see above)\n",
    "        #for layer in model.inner_layers:\n",
    "        #    layer.clamp_params()\n",
    "    print(f\"Epoch {epoch_idx}: Average NLL: {running_loss / len(data_train):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then evaluate our model on test data by computing the average log-likelihood and bits per dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pc.eval()\n",
    "    log_pf = pc_pf(torch.empty((), device=device))  # Compute the partition function once for testing\n",
    "    test_lls = 0.0\n",
    "    for batch, _ in test_dataloader:\n",
    "        log_score = pc(batch.to(device).unsqueeze(dim=-1))\n",
    "        lls = log_score - log_pf\n",
    "        test_lls += lls.sum().item()\n",
    "    average_ll = test_lls / len(data_test)\n",
    "    bpd = -average_ll / (num_variables * np.log(2.0))\n",
    "    print(f\"Average test LL: {average_ll:.3f}\")\n",
    "    print(f\"Bits per dimension: {bpd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4acbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a9727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import gpytorch\n",
    "\n",
    "# from ..functions import RBFCovariance\n",
    "# from ..settings import trace_mode\n",
    "from gpytorch.kernels import Kernel\n",
    "\n",
    "\n",
    "def postprocess_rbf(dist_mat):\n",
    "    return dist_mat.div_(-2).exp_()\n",
    "\n",
    "\n",
    "class TestRBFKernel(Kernel):\n",
    "    r\"\"\"\n",
    "    Computes a covariance matrix based on the RBF (squared exponential) kernel\n",
    "    between inputs :math:`\\mathbf{x_1}` and :math:`\\mathbf{x_2}`:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "       \\begin{equation*}\n",
    "          k_{\\text{RBF}}(\\mathbf{x_1}, \\mathbf{x_2}) = \\exp \\left( -\\frac{1}{2}\n",
    "          (\\mathbf{x_1} - \\mathbf{x_2})^\\top \\Theta^{-2} (\\mathbf{x_1} - \\mathbf{x_2}) \\right)\n",
    "       \\end{equation*}\n",
    "\n",
    "    where :math:`\\Theta` is a :attr:`lengthscale` parameter.\n",
    "    See :class:`gpytorch.kernels.Kernel` for descriptions of the lengthscale options.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        This kernel does not have an `outputscale` parameter. To add a scaling parameter,\n",
    "        decorate this kernel with a :class:`gpytorch.kernels.ScaleKernel`.\n",
    "\n",
    "    Args:\n",
    "        :attr:`ard_num_dims` (int, optional):\n",
    "            Set this if you want a separate lengthscale for each\n",
    "            input dimension. It should be `d` if :attr:`x1` is a `n x d` matrix. Default: `None`\n",
    "        :attr:`batch_shape` (torch.Size, optional):\n",
    "            Set this if you want a separate lengthscale for each\n",
    "            batch of input data. It should be `b` if :attr:`x1` is a `b x n x d` tensor. Default: `torch.Size([])`.\n",
    "        :attr:`active_dims` (tuple of ints, optional):\n",
    "            Set this if you want to compute the covariance of only a few input dimensions. The ints\n",
    "            corresponds to the indices of the dimensions. Default: `None`.\n",
    "        :attr:`lengthscale_prior` (Prior, optional):\n",
    "            Set this if you want to apply a prior to the lengthscale parameter.  Default: `None`.\n",
    "        :attr:`lengthscale_constraint` (Constraint, optional):\n",
    "            Set this if you want to apply a constraint to the lengthscale parameter. Default: `Positive`.\n",
    "        :attr:`eps` (float):\n",
    "            The minimum value that the lengthscale can take (prevents divide by zero errors). Default: `1e-6`.\n",
    "\n",
    "    Attributes:\n",
    "        :attr:`lengthscale` (Tensor):\n",
    "            The lengthscale parameter. Size/shape of parameter depends on the\n",
    "            :attr:`ard_num_dims` and :attr:`batch_shape` arguments.\n",
    "\n",
    "    Example:\n",
    "        >>> x = torch.randn(10, 5)\n",
    "        >>> # Non-batch: Simple option\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        >>> # Non-batch: ARD (different lengthscale for each input dimension)\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=5))\n",
    "        >>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n",
    "        >>>\n",
    "        >>> batch_x = torch.randn(2, 10, 5)\n",
    "        >>> # Batch: Simple option\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        >>> # Batch: different lengthscale for each batch\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(batch_shape=torch.Size([2])))\n",
    "        >>> covar = covar_module(x)  # Output: LazyTensor of size (2 x 10 x 10)\n",
    "    \"\"\"\n",
    "\n",
    "    has_lengthscale = True\n",
    "\n",
    "    def forward(self, x1, x2, diag=False, **params):\n",
    "\n",
    "        x1_ = x1.div(self.lengthscale)\n",
    "        x2_ = x2.div(self.lengthscale)\n",
    "        \n",
    "        # print (\"x1, x2\", x1_, x2_)\n",
    "        \n",
    "        return self.covar_dist(\n",
    "            x1_, x2_, square_dist=True, diag=diag, dist_postprocess_func=postprocess_rbf, postprocess=True, **params\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernel = TestRBFKernel()\n",
    "test_kernel.lengthscale = torch.tensor(3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0114f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernel.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4731298",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernel(x1.squeeze(),x2.squeeze()).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8887c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2c61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef03dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5028f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cirkit1",
   "language": "python",
   "name": "cirkit1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
